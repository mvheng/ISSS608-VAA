[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "In this exercise, we are going to create the following data visualisation by using R packages:\n\nplotting a calendar heatmap by using ggplot2 functions\nplotting a cycle plot by using ggplot2 function\nplotting a slope graph"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\nCGPfunctions package is used to plot slope graphs using newggslopegraph() .\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes, \n               gridExtra, readxl, knitr, data.table, \n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-import",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nIn this hands-on exercise, 3 files are used.\neventlog.csv file will be used to create calendar heat maps. This data file consists of 199,999 rows of time-series cyber attack records by country.\narrivals_by_air.xlsx will be used to create cycle plots. This data file consists of 240 rows of arrival information by country.\nrice.xlsx will be used to create slope graphs. This data file consists of 550 rows of rice yield and production by year in China.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\nrice &lt;- read_csv(\"data/rice.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examine-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examine-the-data",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "2.3 Examine the data",
    "text": "2.3 Examine the data\nExamining the imported data frame before further analysis is always a good practice.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\nkable(head(air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\n\n\n\n\nkable(head(rice))\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\n\n\n\nThere are three columns in attacks table, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores the time zone of the source IP address."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#single-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#single-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "3.1 Single Calendar Heatmap",
    "text": "3.1 Single Calendar Heatmap\nLet’s build a single calendar heatmap.\nBefore we can plot the calendar heatmap, we need to prepare the data and create two customised fields.\n\nStep 1Step 2Final Product\n\n\nStep 1: Deriving customised fields\nWe write a function to derive two new fields namely wkday and hour need to be derived.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {   \n  real_times &lt;- ymd_hms(ts, tz = tz[1], quiet = TRUE)   \n  dt &lt;- data.table(source_country = sc, \n                   wkday = weekdays(real_times),                    \n                   hour = hour(real_times))   \n  return(dt)   \n  }\n\n\n\nStep 2: Deriving the attacks tibble data frame.\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(wkday, levels = wkday_levels),\n        hour  = factor(hour, levels = 0:23))\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, aes(hour, wkday, fill = n)) + \n    geom_tile(color = \"white\", size = 0.1) + \n    theme_minimal() + \n    coord_equal() +\n    scale_fill_gradient(name = \"# of attacks\",\n                        low = \"sky blue\", \n                        high = \"dark blue\") +\n    labs(x = NULL, \n         y = NULL, \n         title = \"Attacks by weekday and time of day\") +\n    theme(axis.ticks = element_blank(),\n          plot.title = element_text(hjust = 0.5),\n          legend.title = element_text(size = 8),\n          legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn\n\n\n\n\nA tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\nA new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing values.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border colour and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to create a two-colour gradient (low-high)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multiple-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "3.2 Multiple Calendar Heatmaps",
    "text": "3.2 Multiple Calendar Heatmaps\nLet’s build multiple heatmaps for the top four countries with the highest number of attacks.\nSimilarly, we need to prepare the data before we can build the multiple heatmaps.\n\nStep 1Step 2Final Product\n\n\nStep 1: Deriving attack by country object\nTo identify the top 4 countries with the highest number of attacks, we need the following:\n\ncount the number of attacks by country,\ncalculate the percentage of attacks by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\n\nStep 2: Preparing the tidy data frame\nLet’s extract the attack records of the top 4 countries from the attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_minimal() + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "In this exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages.\nAt the same time, you will also learn how to reshape data by using tidyr package, and process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore we start making animated graphs, we should first ask ourselves: Does it make sense to go through the effort?\nIf we are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if we are giving a presentation, a few well-placed animated graphics can help an audience connect with our topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#basic-concepts-of-animation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#basic-concepts-of-animation",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#terminology",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#terminology",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "Before we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore we start making animated graphs, we should first ask ourselves: Does it make sense to go through the effort?\nIf we are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if we are giving a presentation, a few well-placed animated graphics can help an audience connect with our topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#loading-the-r-packages",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "2.1 Loading the R Packages",
    "text": "2.1 Loading the R Packages\nWe will use the following R packages in this exercise:\n\ntidyverse, a family of modern R packages specially designed to support data science, analysis, and communication tasks including creating static statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#importing-data",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nFor this exercise, we will use globalPop. It is in xls file format, hence we use read_xls function of the readxl package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\n“Country” and “Continent” are reclassified as categorical data and “Year” is reclassified as numeric integer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "",
    "text": "In this take-home exercise, we are required to select one of the modules of our proposed Shiny application and complete the following tasks:\n\nTo evaluate and determine the necessary R packages needed for our Shiny application are supported in R CRAN\nTo prepare and test the specific R codes that can be run and return the correct output as expected\nTo determine the parameters and outputs that will be exposed on the Shiny applications\nTo select the appropriate Shiny UI components for exposing the parameters determined above.\n\n\n\nOur team has decided to work on visualising and analysing historical weather data from Meteorological Service Singapore. We will create a R Shiny app with user-friendly functionalities, to effectively visualize and analyze weather data.\nThe R Shiny app will consist of the following sections:\n\nHomepage tab: Users have an overview of the dataset used. Users will be able to locate the weather stations in Singapore via a map of Singapore and some interactivity elements.\nEDA tab: Users can explore the distribution and trends of the weather information for specific time periods or stations or regions.\nCDA tab: Users can use statistical analysis to confirm the trends of the weather information.\nTime series forecast tab: Users can explore the time series forecast of temperature or rainfall by selecting the type of forecasting model, the period to forecast etc that they would like to use for univariate time series forecasting.\n\nThis exercise will focus on the last section - time series forecast."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#project-details",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#project-details",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "",
    "text": "Our team has decided to work on visualising and analysing historical weather data from Meteorological Service Singapore. We will create a R Shiny app with user-friendly functionalities, to effectively visualize and analyze weather data.\nThe R Shiny app will consist of the following sections:\n\nHomepage tab: Users have an overview of the dataset used. Users will be able to locate the weather stations in Singapore via a map of Singapore and some interactivity elements.\nEDA tab: Users can explore the distribution and trends of the weather information for specific time periods or stations or regions.\nCDA tab: Users can use statistical analysis to confirm the trends of the weather information.\nTime series forecast tab: Users can explore the time series forecast of temperature or rainfall by selecting the type of forecasting model, the period to forecast etc that they would like to use for univariate time series forecasting.\n\nThis exercise will focus on the last section - time series forecast."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-r-packages",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "2.1 Installing R packages",
    "text": "2.1 Installing R packages\nThe code below uses p_load() of the Pacman package to check if all the required packages are installed on the laptop. If they are, then they will be launched into the R environment.\n\n\n\nPackage\nDescription\n\n\n\n\ntidyverse\nA collection of core packages designed for data science used extensively for data preparation and wrangling.\n\n\nlubridate\nFor manipulating date-times.\n\n\njanitor\nFor quick formatting of data frame columns.\n\n\nfs\nFor retrieving a list of file names in our directory for import into R\n\n\nzoo\nFor irregular time series of numeric vectors/matrices and factors manipulation\n\n\n\n\npacman::p_load(readr, tidyverse, plotly, ggplot2, zoo, forecast, janitor, fs)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-data",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\nBased on the MSS website, we can download the monthly data of a selected climate station each time. As such, I have written a robotic process automation bot using UIPath software to download all the monthly data and store them in the /data/weather folder. Let’s read all the 5552 CSV files downloaded for the 18 weather stations that have records from the year 1980 onwards.\n\nlocale argument in read_csv() is to specify the encoding as Latin-1, as some of the headers contain special characters, like the degree symbol (°). The Latin-1 encoding ensures R can read and process such special characters.\ncol_types argument imports all columns as character data type.\nclean_names() of the janitor package converts into snake case and transliterates special characters such as the degree symbol (°) to ASCII.\n\n\nfilenames &lt;- fs::dir_ls(\"data/weather/\") \n\n# Read all files and clean the column names\ndata &lt;- filenames %&gt;%\n    map_df(~ read_csv(.x, \n                      locale = locale(encoding = \"latin1\"),\n                      col_types = cols(.default = \"character\")\n                      ) %&gt;% \n             janitor::clean_names()\n    ) \n\nglimpse(data)\n\n\n\n\n\n\n\nNote\n\n\n\nAll the 18 weather stations have a total of 168,836 records.\nThe data shows that there are two sets of variables for mean, maximum, and minimum temperature records:\n\nmean_temperature_c, maximum_temperature_c, and minimum_temperature_c\nmean_temperature_a_c, maximum_temperature_a_c, and minimum_temperature_a_c\n\nThis might happen during clean_names() where there is a minor difference in the column names from different files.\n\n\nAs the data is huge and it takes some time to load each file, let’s write into a RDS file and read it for easy use.\n\nwrite_rds(data, \"data/weather.rds\")\n\n\ndata &lt;- read_rds(\"data/weather.rds\")\n\nLet’s read the region data.\n\nregion &lt;- read_csv(\"data/Region.csv\") \nglimpse(region)\n\nRows: 18\nColumns: 2\n$ Station &lt;chr&gt; \"Admiralty\", \"Ang Mo Kio\", \"Boon Lay (East)\", \"Changi\", \"Choa …\n$ Region  &lt;chr&gt; \"North\", \"North-East\", \"West\", \"East\", \"West\", \"West\", \"East\",…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-wrangling",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\nLet’s use coalesce() function to copy the values from the second set of temperature values to the first set and then deselect the second set of columns.\n\ndata$mean_temperature_c &lt;- coalesce(data$mean_temperature_c,\n                                       data$mean_temperature_a_c)\ndata$maximum_temperature_c &lt;- coalesce(data$maximum_temperature_c,\n                                          data$maximum_temperature_a_c)\ndata$minimum_temperature_c &lt;- coalesce(data$minimum_temperature_c,\n                                          data$minimum_temperature_a_c)\n\ndata %&gt;% select(-c(mean_temperature_a_c,\n                     maximum_temperature_a_c,\n                     minimum_temperature_a_c, \n                     mean_wind_speed_km_h, \n                     max_wind_speed_km_h))\n\n# A tibble: 168,439 × 11\n   station    year  month day   daily_rainfall_total_mm highest_30_min_rainfal…¹\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;                   &lt;chr&gt;                   \n 1 Paya Lebar 1981  1     1     0                       \"\\u0097\"                \n 2 Paya Lebar 1981  1     2     0.4                     \"\\u0097\"                \n 3 Paya Lebar 1981  1     3     0                       \"\\u0097\"                \n 4 Paya Lebar 1981  1     4     3.3                     \"\\u0097\"                \n 5 Paya Lebar 1981  1     5     0                       \"\\u0097\"                \n 6 Paya Lebar 1981  1     6     0.8                     \"\\u0097\"                \n 7 Paya Lebar 1981  1     7     4.6                     \"\\u0097\"                \n 8 Paya Lebar 1981  1     8     2.3                     \"\\u0097\"                \n 9 Paya Lebar 1981  1     9     0.3                     \"\\u0097\"                \n10 Paya Lebar 1981  1     10    0                       \"\\u0097\"                \n# ℹ 168,429 more rows\n# ℹ abbreviated name: ¹​highest_30_min_rainfall_mm\n# ℹ 5 more variables: highest_60_min_rainfall_mm &lt;chr&gt;,\n#   highest_120_min_rainfall_mm &lt;chr&gt;, mean_temperature_c &lt;chr&gt;,\n#   maximum_temperature_c &lt;chr&gt;, minimum_temperature_c &lt;chr&gt;\n\nglimpse(data)\n\nRows: 168,439\nColumns: 16\n$ station                     &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\", …\n$ year                        &lt;chr&gt; \"1981\", \"1981\", \"1981\", \"1981\", \"1981\", \"1…\n$ month                       &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ day                         &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9…\n$ daily_rainfall_total_mm     &lt;chr&gt; \"0\", \"0.4\", \"0\", \"3.3\", \"0\", \"0.8\", \"4.6\",…\n$ highest_30_min_rainfall_mm  &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\…\n$ highest_60_min_rainfall_mm  &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\…\n$ highest_120_min_rainfall_mm &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\…\n$ mean_temperature_c          &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\…\n$ maximum_temperature_c       &lt;chr&gt; \"30.8\", \"29.5\", \"30.4\", \"30.7\", \"27.2\", \"3…\n$ minimum_temperature_c       &lt;chr&gt; \"22.7\", \"23.1\", \"23.5\", \"23.5\", \"23.2\", \"2…\n$ mean_wind_speed_km_h        &lt;chr&gt; \"14.3\", \"9.4\", \"11.7\", \"9.4\", \"9.1\", \"9.6\"…\n$ max_wind_speed_km_h         &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\…\n$ mean_temperature_a_c        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ maximum_temperature_a_c     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ minimum_temperature_a_c     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nRemove weird characters\nThere are some weird characters in the data frame. Let’s replace them with NA.\n\ndata &lt;- data %&gt;%\n  mutate_all(~ ifelse(. == \"\\u0097\", NA, .))\n\nTidy up the weather data\nFinally, let’s clean up the weather data and create a column for date, change the necessary columns to numeric, and shorten the column names for simplicity.\n\nweather &lt;- data %&gt;% \n  mutate(station = station,\n       DDate = make_date(year = year, month = month, day = day),\n       year = as.numeric(year),\n       month = lubridate::month(DDate, label = TRUE),         \n       day = as.numeric(day),\n       daily_rainfall_total_mm = as.numeric(daily_rainfall_total_mm), \n       highest_30_min_rainfall_mm = as.numeric(highest_30_min_rainfall_mm), \n       highest_60_min_rainfall_mm = as.numeric(highest_60_min_rainfall_mm),\n       highest_120_min_rainfall_mm = as.numeric(highest_120_min_rainfall_mm),\n       mean_temperature_c = as.numeric(mean_temperature_c), \n       maximum_temperature_c = as.numeric(maximum_temperature_c), \n       minimum_temperature_c = as.numeric(minimum_temperature_c)) %&gt;% \n  rename(\n    Station = station,\n    Year = year,\n    Month = month,\n    Day = day,\n    Rainfall = daily_rainfall_total_mm,\n    Rainfall30 = highest_30_min_rainfall_mm,\n    Rainfall60 = highest_60_min_rainfall_mm,\n    Rainfall120 = highest_120_min_rainfall_mm,\n    MeanTemp = mean_temperature_c,\n    MaxTemp = maximum_temperature_c,\n    MinTemp = minimum_temperature_c\n  ) %&gt;% \n  subset(select = -c(mean_temperature_a_c,\n                     maximum_temperature_a_c,\n                     minimum_temperature_a_c, \n                     mean_wind_speed_km_h, \n                     max_wind_speed_km_h))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#merge-datasets",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#merge-datasets",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "2.4 Merge datasets",
    "text": "2.4 Merge datasets\n\nweather &lt;- merge(weather, region, by= \"Station\")\nglimpse(weather)\n\nRows: 147,833\nColumns: 13\n$ Station     &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admir…\n$ Year        &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011…\n$ Month       &lt;ord&gt; Jan, Jan, Feb, Feb, Feb, Feb, Feb, Feb, Mar, Feb, Feb, Feb…\n$ Day         &lt;dbl&gt; 13, 14, 13, 8, 9, 10, 11, 12, 25, 14, 15, 16, 17, 18, 19, …\n$ Rainfall    &lt;dbl&gt; 0.0, 11.4, 0.0, 20.0, 0.0, 38.0, 14.8, 1.6, 0.0, 0.0, 9.0,…\n$ Rainfall30  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Rainfall60  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Rainfall120 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ MeanTemp    &lt;dbl&gt; 26.7, 25.5, 27.2, 26.8, 26.9, 26.8, 26.6, 27.0, 28.7, 27.2…\n$ MaxTemp     &lt;dbl&gt; 29.8, 29.4, 32.2, 33.1, 32.1, 34.6, 33.4, 33.5, 31.8, 32.3…\n$ MinTemp     &lt;dbl&gt; 24.2, 24.0, 24.5, 23.5, 24.2, 22.3, 23.8, 24.3, 25.7, 24.6…\n$ DDate       &lt;date&gt; 2011-01-13, 2011-01-14, 2011-02-13, 2011-02-08, 2011-02-0…\n$ Region      &lt;chr&gt; \"North\", \"North\", \"North\", \"North\", \"North\", \"North\", \"Nor…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#create-subsets-of-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#create-subsets-of-data",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "2.5 Create subsets of data",
    "text": "2.5 Create subsets of data\nLet’s create subsets of weather data for only Temperature or Rainfall variables.\nEach Temperature or Rainfall variable has 2 subsets - one with region grouping, one without region grouping.\n\nweather$DDate &lt;- as.Date(paste(weather$Year, \n                            weather$Month,\n                            1, sep = \"-\"), format = \"%Y-%b-%d\")\nTemp_YM &lt;- weather %&gt;% \n   group_by(Year, Month, Region) %&gt;% \n   reframe(DDate = DDate,\n            AveMeanTemp = round(mean(MeanTemp, na.rm = TRUE),1),\n            MaxMaxTemp = max(MaxTemp, na.rm = TRUE),\n            MinMinTemp = min(MinTemp, na.rm = TRUE)) %&gt;% \n   distinct() %&gt;% \n   ungroup() %&gt;% \n   filter(!is.na(AveMeanTemp))\n\nTemp_YM_allR &lt;- weather %&gt;% \n   group_by(Year, Month) %&gt;% \n   reframe(DDate = DDate,\n            AveMeanTemp = round(mean(MeanTemp, na.rm = TRUE),1),\n            MaxMaxTemp = max(MaxTemp, na.rm = TRUE),\n            MinMinTemp = min(MinTemp, na.rm = TRUE)) %&gt;% \n   distinct() %&gt;%\n   ungroup() %&gt;% \n   filter(!is.na(AveMeanTemp))\n\nRain_YM &lt;- weather %&gt;% \n   group_by(Region, Year, Month) %&gt;% \n   reframe(DDate = DDate,\n            MeanRainfall = round(sum(Rainfall, na.rm = TRUE),1),\n            HighRainfall30 = sum(Rainfall30, na.rm = TRUE),\n            HighRainfall60 = sum(Rainfall60, na.rm = TRUE),\n            HighRainfall120 = sum(Rainfall120, na.rm = TRUE)) %&gt;% \n   distinct() %&gt;%\n   ungroup() %&gt;% \n   filter(!is.na(MeanRainfall))\n\nRain_YM_allR &lt;- weather %&gt;% \n   group_by(Year, Month) %&gt;% \n   reframe(DDate = DDate,\n            MeanRainfall = sum(Rainfall, na.rm = TRUE),\n            HighRainfall30 = sum(Rainfall30, na.rm = TRUE),\n            HighRainfall60 = sum(Rainfall60, na.rm = TRUE),\n            HighRainfall120 = sum(Rainfall120, na.rm = TRUE)) %&gt;% \n   distinct() %&gt;%\n   ungroup() %&gt;% \n   filter(!is.na(MeanRainfall))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#create-a-function",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#create-a-function",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "4.1 Create a function",
    "text": "4.1 Create a function\nThis function will take in all the five parameters that users set, generate the forecasting values and plot the graph using plotly().\nFor the Seasonal & Trend Decomposition method, there are 3 additional plots to show (trend, seasonal and residual).\n\nGenerateTS &lt;- function(variable_name, model_name, select_region,\n                       forecast_year, conf_level) {\n  \n   if (variable_name == \"Temp\") {\n      if (select_region != \"All\") {\n          temp &lt;- Temp_YM %&gt;%\n            filter(Region == select_region) %&gt;% \n            rename(Value = AveMeanTemp) \n      } else {\n         temp &lt;- Temp_YM_allR %&gt;% \n            rename(Value = AveMeanTemp)\n      }\n      displayText = \"Temp\"\n      displayUnit = \"°C\"\n    } else {\n      if (select_region != \"All\") {\n          temp &lt;- Rain_YM %&gt;%\n            filter(Region == select_region) %&gt;% \n            rename(Value = MeanRainfall) \n      } else {\n         temp &lt;- Rain_YM_allR %&gt;% \n            rename(Value = MeanRainfall)\n       }\n      displayText = \"Rainfall\"\n      displayUnit = \"mm\"\n    }\n   \n   minDate = min(temp$DDate)\n   maxDate = max(temp$DDate)\n   ts_data &lt;- ts(temp$Value, \n                 start = c(year(minDate), month(minDate)), \n                 end = c(year(maxDate), month(maxDate)), frequency = 12)  \n      \n   switch(model_name,\n      \"ARIMA\" = { model = auto.arima(ts_data, p = 5, seasonal = TRUE)},\n      \"HoltWinters\" = { model &lt;- HoltWinters(ts_data)},\n      \"STL\" = {model &lt;- stl(ts_data, s.window=\"periodic\") }\n   )\n    \n   forecast_values &lt;- forecast(model, h = forecast_year * 12, \n                             level = c(conf_level))\n   actual_values &lt;- ts_data[(length(ts_data) - \n                        length(forecast_values$mean) + 1):length(ts_data)]\n   \n   forecast_df &lt;- data.frame(Date = time(forecast_values$mean), \n                           Forecast = forecast_values$mean, \n                           LowerV = forecast_values$lower, \n                           UpperV = forecast_values$upper)\n   \n   actual_df &lt;- data.frame(Date = time(ts_data), Actual = ts_data)\n   forecast_df$Period &lt;- format(as.Date(forecast_df$Date, \n                                      origin = minDate), \"%Y-%m\")\n   actual_df$Period &lt;- format(as.Date(actual_df$Date, \n                                      origin = minDate), \"%Y-%m\")\n   \n   LowerV &lt;- paste(\"X\", as.character(conf_level), \".\", sep = \"\")\n   HigherV &lt;- paste(\"X\", as.character(conf_level), \"..1\", sep = \"\")\n   names(forecast_df)[names(forecast_df) == HigherV] &lt;- \"UpperV\"\n   names(forecast_df)[names(forecast_df) == LowerV] &lt;- \"LowerV\"\n   \n   #cannot go negative\n   forecast_df$LowerV &lt;- pmax(forecast_df$LowerV, 0)\n   \n   g &lt;- plot_ly() %&gt;%\n         add_lines(data = forecast_df, x = ~Date, y = ~Forecast, \n             name = \"Forecast\", line = list(color = 'blue'), \n             hoverinfo = \"text\", \n             text = ~paste(\"Year-Month: \", Period, \n                           \"&lt;br&gt;\", displayText, \": \", \n                           round(Forecast, 1), displayUnit))%&gt;%\n         add_lines(data = actual_df, x = ~Date, y = ~Actual, \n                  name = \"Actual\", line = list(color = 'red'), \n                  hoverinfo = \"text\", \n                  text = ~paste(\"Year-Month: \", Period, \n                                \"&lt;br&gt;\", displayText, \": \", \n                                Actual, displayUnit)) %&gt;%\n         add_ribbons(data = forecast_df, x = ~Date, \n                     ymin = ~LowerV, ymax = ~UpperV, \n                    name = paste(conf_level, \"% CI\"), \n                    fillcolor = 'lightblue',\n                    opacity = 0.5,\n                    hoverinfo = \"text\", \n                    text = ~paste(\"Year-Month: \", Period, \n                                  \"&lt;br&gt;CI:\", round(LowerV,1), displayUnit,\n                                  \"-\", round(UpperV,1), displayUnit)) %&gt;%\n         layout(title = paste(\"Forecasting \", displayText,\n                              \" for the next \", forecast_year,\n                              \" years using \", model_name),\n               xaxis = list(title = \"Year\"),\n               yaxis = list(title = displayText))\n         \n   if (model_name == \"STL\") {\n     par(mfrow=c(3, 1))  # Set up a 3x1 layout for plots\n     trend &lt;- model$time.series[, \"trend\"]\n     seasonal &lt;- model$time.series[, \"seasonal\"]\n     remainder &lt;- model$time.series[, \"remainder\"]\n     # Plot trend component\n     plot(time(ts_data), trend, type=\"l\", col=\"blue\",\n          main=\"Trend Component\", xlab=\"Time\", ylab=\"Trend\")\n     \n     # Plot seasonal component\n     plot(time(ts_data), seasonal, type=\"l\", col=\"green\", \n          main=\"Seasonal Component\", xlab=\"Time\", ylab=\"Seasonal\")\n     \n     # Plot remainder (residual) component\n     plot(time(ts_data), remainder, type=\"l\", col=\"red\", \n          main=\"Remainder Component\", xlab=\"Time\", ylab=\"Remainder\")\n     \n     # Reset par to default settings\n     par(mfrow=c(1, 1))\n   } \n   \n   g\n}\n\n\n\n\n\n\n\nNote\n\n\n\nAs the forecast lower bound values may go negative, we would need to limit them to minimum 0 value as we do not have negative temperature or rainfall in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#test-the-function",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#test-the-function",
    "title": "Take-home Exercise 4: Prototyping Modules for Shiny Application",
    "section": "4.2 Test the function",
    "text": "4.2 Test the function\nLet’s test the function with various parameters:\n\nTest #1Test #2Test #3\n\n\nForecast temperature using the ARIMA method for North region data over the next 10 years with a 95% confidence interval.\n\nGenerateTS(\"Temp\", \"ARIMA\", \"North\", 10, 95)\n\n\n\n\n\n\n\nForecast temperature using the Holt-Winters method for East region data over the next 5 years with a 99% confidence interval.\n\nGenerateTS(\"Temp\", \"HoltWinters\", \"East\", 5, 99)\n\n\n\n\n\n\n\nForecast rainfall using the STL method for all region data over the next 5 years with a 90% confidence interval.\n\nGenerateTS(\"Rain\", \"STL\", \"All\", 5, 90)\n\n\n\n\n\n\n\n\n\n\n\nTime series clustering | Data Analysis (geomoer.github.io)\nExploring other forecasting methods.\n\nlibrary(prophet)\n\n# Create a dataframe for Prophet\nactual_df &lt;- data.frame(ds = Temp_YM_allR$DDate, y = Temp_YM_allR$AveMeanTemp)\n\n# Fit the Prophet model\nmodel &lt;- prophet(interval.width = 0.95)\nmodel &lt;- fit.prophet(model, actual_df)\n\n# Make future predictions\nfuture &lt;- make_future_dataframe(model, periods = 10*12, freq = 'months')\nforecast_values &lt;- predict(model, future)\n\nstr(forecast_values)\n    forecast_df &lt;- data.frame(\n  Date = forecast_values$ds,  # Timestamps\n  Forecast = forecast_values$yhat,  # Forecasted values\n  LowerV = forecast_values$yhat_lower,  # Lower bounds of forecasts\n  UpperV = forecast_values$yhat_upper  # Upper bounds of forecasts\n)\n\n# Optionally, you can convert 'Date' column to Date type\nforecast_df$Date &lt;- as.Date(forecast_df$Date)    \n    forecast_df$YearMonth &lt;- format(as.Date(forecast_df$Date, \n                                            origin = minDate), \"%Y-%m\")\n    \n    #cannot go negative\n    forecast_df$LowerV &lt;- pmax(forecast_df$LowerV, 0)\n\n  \nplot_ly() %&gt;%\n  add_lines(data = forecast_df, x = ~Date, y = ~Forecast, name = 'Forecast', line = list(color = 'blue')) %&gt;%\n  add_lines(data = forecast_df, x = ~Date, y = ~LowerV, name = 'Lower Bound', line = list(color = 'red', dash = 'dot')) %&gt;%\n  add_lines(data = forecast_df, x = ~Date, y = ~UpperV, name = 'Upper Bound', line = list(color = 'green', dash = 'dot')) %&gt;%\n  add_trace(data = actual_df, x = ~Date, y = ~y, name = 'Actual', type = 'scatter', mode = 'lines', line = list(color = 'black')) %&gt;%\n  layout(title = 'Temperature Forecast',\n         xaxis = list(title = 'Date'),\n         yaxis = list(title = 'Temperature'))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "",
    "text": "In this take-home exercise, we are supposed to:\n\ncritic one of the Take-home Exercise 1 submissions in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices\nremake the original design by using ggplot2, ggplot2 extensions, and tidyverse packages.\n\n\n\nThe code below uses p_load() of the Pacman package to check if all the required packages are installed on the laptop. If they are, then they will be launched into the R environment.\n\npacman::p_load(tidyverse, haven, dplyr, ggthemes, patchwork, plyr, \n               ggpubr, colorspace, reshape2, ggdist, ggridges )\n\n\n\n\nWe only use the PISA 2022 data set for Singapore.\nRows with NA are omitted too.\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\nstu_qqq_SG &lt;- stu_qqq_SG %&gt;% \n  select(\"CNTSCHID\", \"CNTSTUID\", \"STRATUM\", \"ST004D01T\", \"ESCS\", \"ST255Q01JA\",\n           \"PV1MATH\",\"PV1READ\", \"PV1SCIE\") %&gt;% na.omit()\n\nstu_qqq_SG &lt;- rename(stu_qqq_SG, c(\"ST004D01T\" = \"Gender\",\n                                   \"ST255Q01JA\" = \"Books\",\n                                  \"PV1MATH\" = \"Mathematics\", \n                                 \"PV1SCIE\" = \"Science\",\n                                 \"PV1READ\" = \"Reading\")) \n\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 1] &lt;- \"Female\"\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 2] &lt;- \"Male\"\n\nstu_qqq_SG = stu_qqq_SG %&gt;%\n  mutate(Books = recode(Books, \n                        \"01\" = \"0\",\n                        \"02\" = \"1-10\",\n                        \"03\" = \"11-25\",\n                        \"04\" = \"26-100\",\n                        \"05\" = \"101-200\",\n                        \"06\" = \"201-500\",\n                        \"07\" = \"&gt;500\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "",
    "text": "The code below uses p_load() of the Pacman package to check if all the required packages are installed on the laptop. If they are, then they will be launched into the R environment.\n\npacman::p_load(tidyverse, haven, dplyr, ggthemes, patchwork, plyr, \n               ggpubr, colorspace, reshape2, ggdist, ggridges )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-pisa-data",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "",
    "text": "We only use the PISA 2022 data set for Singapore.\nRows with NA are omitted too.\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\nstu_qqq_SG &lt;- stu_qqq_SG %&gt;% \n  select(\"CNTSCHID\", \"CNTSTUID\", \"STRATUM\", \"ST004D01T\", \"ESCS\", \"ST255Q01JA\",\n           \"PV1MATH\",\"PV1READ\", \"PV1SCIE\") %&gt;% na.omit()\n\nstu_qqq_SG &lt;- rename(stu_qqq_SG, c(\"ST004D01T\" = \"Gender\",\n                                   \"ST255Q01JA\" = \"Books\",\n                                  \"PV1MATH\" = \"Mathematics\", \n                                 \"PV1SCIE\" = \"Science\",\n                                 \"PV1READ\" = \"Reading\")) \n\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 1] &lt;- \"Female\"\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 2] &lt;- \"Male\"\n\nstu_qqq_SG = stu_qqq_SG %&gt;%\n  mutate(Books = recode(Books, \n                        \"01\" = \"0\",\n                        \"02\" = \"1-10\",\n                        \"03\" = \"11-25\",\n                        \"04\" = \"26-100\",\n                        \"05\" = \"101-200\",\n                        \"06\" = \"201-500\",\n                        \"07\" = \"&gt;500\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distributions-of-mathsreadingscience-scores",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distributions-of-mathsreadingscience-scores",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "2.1 Distributions of Maths/Reading/Science scores",
    "text": "2.1 Distributions of Maths/Reading/Science scores\n\n2.1.1 Original design\nLet’s look at this density chart that shows the distribution of 3 subject scores.\n\n\n\n2.1.2 Critique\nClarity\n\nThe title has given a clear interpretation of what readers can expect when looking at the chart, i.e. Mathematics is a better-performing subject than Science and Reading. 👍\nThere is a subtitle to indicate what kind of chart it is. 👍\nMissing caption to indicate the source of the data. ⚠️\nThe axes are labelled clearly with x-axis tick marks provided. All 3 distributions use the same x-axis range.👍\nThere is a legend for the colours, however, readers who are not good at statistics might not know what the quartiles 1, 2, 3, or 4 mean. Maybe we could use percentile instead of quartile and label 1 as &lt;=25th, 2 as 26th-50th, 3 as 51th-75th, and 4 as &gt;75th. ⚠️\nReaders might not know how the conclusion is made - Mathematics is a better-performing subject - is it due to height of distribution, area of yellow range etc? Statistics summary (e.g. mean or median) could be added to help readers correlate better. ⚠️\n\nAesthetics\n\nThe bright colour contrast is appealing. 👍\nCombining the three distributions in a chart is easy to make a comparison. 👍\nClean background colour to make the distributions stand out. 👍\n\n\n\n2.1.3 Design Considerations\nDraft 1\nLet’s sketch the chart with dotted lines to represent the mean of each subject.\n\nThough mean lines help to make the comparison easier, we would have 5 colours on the chart (the quartile colours and the mean line) that might confuse readers. So how can we represent the quartiles differently?\nDraft 2\nWe can use a box plot to represent the quartiles and also include outliers to tell the spread better.\nAdding rainclouds (data dots) might provide more information, however, it might make the chart more complicated and the data dots might not be so meaningful in deriving the conclusion.\n\n\n\n2.1.4 Visualisation Make-over\n\nBestDraft\n\n\nBest make-over.\n\n\nShow the code\ntemp_Data &lt;- stu_qqq_SG[, c(\"Mathematics\", \"Science\", \"Reading\")]\ntemp_Data &lt;- melt(temp_Data, variable.name = \"Subject\")\n\nggplot(temp_Data, aes(x = value, y = Subject)) +\n  stat_halfeye(aes(fill = Subject), \n               adjust = 0.5,\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -1, size = 3.5, \n               aes( label= paste0(\"mean = \",round(after_stat(x), 1)))) +\n  labs(y = NULL, x = \"scores\",\n       title = \"Singapore Students Generally Perform Better in\\nMathematics than Science & Reading in PISA 2022\",\n       subtitle = \"Distribution of Mathematics, Science and Reading Scores with mean scores\",\n       caption = \"PISA 2022 Singapore results\") +\n  theme(axis.title = element_text(angle  =360, vjust =.5,\n                                  hjust = 1, face = \"bold\",\n                                  colour = \"navy\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\", \n        plot.title = element_text(size = 14, face = \"bold\",\n                                  colour = \"navy\"))\n\n\n\n\n\n\n\nIt is very tough to use different colours for the mean lines as the diagram has too many colours. Hence, this draft is not good.\n\n\nShow the code\nmMath = mean(stu_qqq_SG$Mathematics)\nmScience = mean(stu_qqq_SG$Science)\nmReading = mean(stu_qqq_SG$Reading)\n\nggplot(temp_Data, aes(x = value, y = Subject,\n           fill = factor(after_stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\", alpha = 0.8) +\n  labs(title = \"Singapore Students Generally Perform Better in\\nMathematics than Science & Reading\",\n        subtitle = \"Distribution of Mathematics, Science and Reading Scores\") +\n  geom_vline(aes(xintercept = mMath),\n             color=\"red\", \n             linetype=\"dashed\", \n             linewidth=1,\n             alpha = 0.5) +\n  geom_vline(aes(xintercept = mScience),\n             color=\"red\", \n             linetype=\"dashed\", \n             linewidth=1,\n             alpha = 0.5) +\n  geom_vline(aes(xintercept = mReading),\n             color=\"red\", \n             linetype=\"dashed\", \n             linewidth=1,\n             alpha = 0.5) +\n  theme(plot.title = element_text(size = 14, face = \"bold\",\n                                  colour = \"navy\"))\n\n\n\n\n\n\n\n\nImprovements made:\n\nChart Type: Replacing the quartiles shading with boxplots to show the interquartile range and median marks. We can also see where the outliers are and the frequency of outliers happens more in Reading at the lower end as compared to Science and Mathematics.\nStatistical Values: Stating the mean value for each subject will allow users to make easier comparisons with the median marks. We can see that the mean and median score for Mathematics is higher than for Science and Reading. The mean score is lower than the median score for all 3 subjects.\nLayout: Legend is not required now, so removing it will give more space for the plots.\nMessage Context: Include the context (PISA 2022) in the title.\nReference: A caption is included to show the source of the data.\nSubtitle: The subtitle includes mean scores so that readers may infer that mean scores are used to make comparisons, hence the statement made in the title.\nAesthetic enhancements: The colours used for different subjects are for aesthetic purposes and should be consistently used for the subsequent charts that involve subjects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#science-performance-versus-gender",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#science-performance-versus-gender",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "2.2 Science Performance versus Gender",
    "text": "2.2 Science Performance versus Gender\n\n2.2.1 Original design\nLet’s look at this density chart to show the distribution of Science scores among the genders.\n\n\n\n2.2.2 Critique\nClarity\n\nThe title has given a clear interpretation of what readers can expect when looking at the chart, i.e. Girls are not necessarily weaker in Science. 👍 However, we have no idea how this conclusion is made as the 2 density graphs look similar! ⚠️\nThere is a subtitle to indicate what kind of chart it is. 👍\nMissing caption to indicate the source of the data. ⚠️\nThe axes are labelled clearly with axes tick marks provided. 👍\nThere is a colour legend for the gender.👍\nWhat do the 2 vertical lines represent? There is no information at all! ⚠️\nWhat does density mean? Readers might not know how to interpret. ⚠️\n\nAesthetics\n\nThe colours used for males and females are typical. 👍\nClean background colour to make the graphs stand out. 👍\n\n\n\n2.2.3 Design Considerations\nThe distributions of Science scores for Females and Males are very similar, hence it is not suitable to plot the two distributions in overlapping mode.\nDraft 1\nWe should separate the two distributions and also include the statistical values (such as the mean) to allow readers to understand how the conclusion is derived.\n\nAs the histograms have similar shapes, it might be hard for readers to judge based on mean values.\nDraft 2\nLet’s use boxplots to compare the distribution. Readers will see that the interquartile range (IQR), median and mean values are similar for both genders.\n\n\n\n2.2.4 Visualisation Make-over\n\nBestDraft\n\n\nBest make-over\n\n\nShow the code\nggplot(data = stu_qqq_SG, aes(x = Gender, y = Science,\n                              fill = Gender)) +\n  geom_boxplot(notch = TRUE) +\n  stat_summary(fun = \"mean\",\n               geom = \"point\",\n               color = \"darkred\",\n               size = 2) +\n  stat_summary(fun = mean, geom = \"text\", \n               color = \"black\", vjust = 1.5, \n               aes(label = paste0(\"Mean = \", round(..y.., 2)))) +\n  labs(y = \"Score\", \n      title = \"Girls perform well in Science, similarly to boys\",\n      subtitle = \"Boxplot of Science performance by Gender\",\n      caption = \"PISA 2022 Singapore results\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 14, face = \"bold\",\n                                  colour = \"navy\"))\n\n\n\n\n\n\n\nThe histograms are not easy to make comparisons as the shapes are similar for both genders. Hence, this draft is not suitable.\n\n\nShow the code\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 1] &lt;- \"Female\"\nstu_qqq_SG$Gender[stu_qqq_SG$Gender == 2] &lt;- \"Male\"\n\nf = stu_qqq_SG %&gt;%\n  filter(Gender == \"Female\")\nm = stu_qqq_SG %&gt;%\n  filter(Gender == \"Male\")\n\np1 &lt;- ggplot(f, aes(x = Science)) +\n  geom_histogram(bins = 20, \n                 boundary = 100, alpha = 0.5,\n                 color = \"grey\", fill = \"darkred\") +\n  xlim(200, 850) +\n  geom_vline(aes(xintercept = mean(Science)),\n             color=\"darkred\", \n             linetype=\"dashed\", \n             linewidth=1,\n             alpha = 0.5) +\n  annotate(geom = \"text\", x = 580, y = 420,  \n           label = paste0(\"mean = \", round(mean(f$Science),2)),\n           vjust = -0.5,  \n           hjust = 1.2,\n           size = 3.5, color = \"darkred\") +\n  labs(y = \"count\", x = NULL, subtitle = \"Girls\") +\n  theme_minimal()\n\np2 &lt;- ggplot(m, aes(x = Science)) +\n  geom_histogram(bins = 20, \n                 boundary = 100, alpha = 0.5,\n                 color = \"grey\", fill = \"blue\") +\n  xlim(200, 850) +\n  geom_vline(aes(xintercept = mean(Science)),\n             color=\"blue\", \n             linetype=\"dashed\", \n             linewidth=1,\n             alpha = 0.5) +\n  annotate(geom = \"text\", x = 580, y = 400,  \n           label = paste0(\"mean = \", round(mean(m$Science),2)),\n           vjust = -0.5,  \n           hjust = 1.2,\n           size = 3.5, color = \"blue\") +\n  labs(y = \"count\", x = \"score\", subtitle = \"Boys\") +\n  theme_minimal()\n\n(p1 / p2) +\n  plot_layout(axis_titles = \"collect\", guides = \"collect\") +\n  plot_annotation(title = \"Girls perform well in Science, similarly to boys\",\n                  subtitle = \"Histogram of Science performance by Gender\",\n                  caption = \"PISA 2022 Singapore results\", \n                  theme = theme(plot.title = \n                                  element_text(size = 14, face =\"bold\",\n                                               colour = \"navy\"))) \n\n\n\n\n\n\n\n\nImprovements made:\n\nChart Type: Replace the density graphs with boxplots to allow readers to compare the 5 summary points (min, max, median, first and third quartiles). Readers can also see the number of outliers in each gender.\nStatistical Values: The mean score of each gender is also shown in the boxplots to make the comparison easier.\nClarity: No overlapping of the distributions as the boxplots are placed side by side with the same y-axis scale.\nClear Message: “Girls are not necessarily weaker in Science” may seem to be defending an accusation statement that girls are weaker in Science as compared to boys. To make the message neutral, the title has changed to mention that both genders did similarly well.\nReference: A caption is provided to indicate the source of the data.\nAesthetic enhancements: The colours used for different genders are for aesthetic purposes and should be consistently used for the subsequent charts that involve gender."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#reading-performance",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#reading-performance",
    "title": "Take-home Exercise 2: Data Visualisation Makeover",
    "section": "2.3 Reading Performance",
    "text": "2.3 Reading Performance\n\n2.3.1 Original design\nLet’s look at this density chart to show the Reading performance among the students who have read different numbers of books.\n\n\n\n2.3.2 Critique\nClarity\n\nThe title suggests causation between the number of books and Reading scores. ⚠️ The title should be rephrased such that it states possible correlation instead of causation.\nThere is a subtitle to indicate what kind of chart it is. 👍\nMissing caption to indicate the source of the data. ⚠️\nThe axes are labelled clearly with axes tick marks provided. 👍\nWhat does the two colours mean? Do we look at the division line to make a comparison or the area of each colour (which is the same for all)⚠️\n\nAesthetics\n\nThe contrasting colours used are appealing. 👍\nClean background colour to make the graphs stand out. 👍\n\n\n\n2.2.3 Design Considerations\nWe need to make the comparison visible to the readers so that they can get the same conclusion as the title suggested.\nLet’s replace the density graphs with boxplots to allow readers to see the 5 summary statistics for each book category.\n\nCan we add more information to the chart? What about the number of students in each book category, so that we can show that more students in the category do not necessarily mean higher score?\n\n\n2.3.4 Visualisation Make-over\n\n\nShow the code\nr = stu_qqq_SG %&gt;% \n  select(Books, Reading) %&gt;%\n  mutate(Books = fct_relevel(Books, \n                              \"0\", \n                              \"1-10\",\n                              \"11-25\",\n                              \"26-100\",\n                              \"101-200\",\n                              \"201-500\",\n                              \"&gt;500\"))\n                        \nggplot(r, aes(x = Books)) +\n  geom_bar(aes(y = ..count..), stat = \"count\", fill = \"royalblue1\") +\n  geom_boxplot(aes(y = Reading * 3), position = \"dodge\", width = 0.2, \n               fill = \"sienna2\") +\n  scale_y_continuous(name = \"Number of Students\", \n                     sec.axis = sec_axis(~ . / 3, name = \"Score\")) +\n  theme_minimal() +\n  labs(x = \"Number of Books\",\n        title = \"Students with more books at home tend to do better in Reading\",\n        subtitle = \"Distribution of students based on number of books at home, and their Reading performance\",\n        caption = \"PISA 2022 Singapore results\\nBoxplot - refers to score axis\\nBarchart - refers to number of students axis\") +\n  theme(plot.title = element_text(size = 14, face = \"bold\", colour = \"navy\"),\n        axis.title.y.left = element_text(colour=\"royalblue\"),\n        axis.title.y.right = element_text(colour=\"sienna\"))\n\n\n\n\n\nImprovements made:\n\nChart Type: Replace the density graphs with boxplots to show the 5 summary statistics. Readers can compare that the median score is higher for students who have more books as compared to those who have less than 10 books.\nUseful Information: Readers can see the number of students in each book category from the bar chart, which is additional information from the original design.\nTitle: The title has changed to a non-causation statement, to suggest a correlation between the number of books at home and reading scores.\nReference: A caption is provided to indicate the source of the data.\nAesthetic enhancements: Colours are added - one for box plots on the reading performance and one for the bars on the student counts. This will allow readers to focus on each colour comparison.\nAxes adjustment: The x-axis label is stated with only the numerical values (e.g. ‘1-10’ as compared to ‘1-10 books’) as the x title already indicates that it is referring to books. This prevents the x-axis labels from being overcrowded.\nInstructions: Since there are two y-axes (one for each chart), instructions are stated at the bottom right corner so that readers know which axis is for which chart. The y-axis titles are coloured in the shades of their respective chart fill."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html",
    "title": "In-class Exercise 7b: Geospatial Analysis using R",
    "section": "",
    "text": "This exercise is to give us more practices on handling geospatial data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html#installing-and-loading-the-packages",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html#installing-and-loading-the-packages",
    "title": "In-class Exercise 7b: Geospatial Analysis using R",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\nterra for handling spatial data analysis with vector (points, lines, polygons) and raster (grid) data.\nviridis: colour library\n\n\npacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html#load-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07b.html#load-data",
    "title": "In-class Exercise 7b: Geospatial Analysis using R",
    "section": "2.2 Load data",
    "text": "2.2 Load data\nThe data we have is the rainfall data from Paya Lebar Weather station and the latitude and longitude of all weather stations.\n\nrfstations &lt;- read_csv(\"data/aspatial/RainfallStation.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex07/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Build a Shiny App!",
    "section": "",
    "text": "1. Basic of Shiny\nThese are the 3 essential parts of building a Shiny app.\n\nUI interface for us to control the layout, appearance, and type of controls of the app. (This is what users will click or choose)\nServer function for us to build the output display in the forms of plot, text, table, image etc.\nShinyApp is to create to shiny app object.\n\n\n\n\n2. Hands-on Practice\nWe have learned how to create a simple Shiny app that allows users to choose the subject and bins of the histogram to be displayed.\n\nThis app is also published on this website."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Tableau Hands-on Part 2",
    "section": "",
    "text": "In this exercise, we have some more hands-on on Tableau.\n\nThe dashboard consists of several charts. One of the charts has a chart in the tooltip. You can view it here.\n\n\n\nCreate a story to tell the message to the audience. You can view it here.\n\n\n\nMaking charts interactive with other charts. You can view it here."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "",
    "text": "In this In-class exercise, two R packages will be used. They are\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "",
    "text": "In this In-class exercise, two R packages will be used. They are\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into the R environment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\nLet’s filter data by Country ID = SGP (Singapore).\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#filtering-and-saving-filtered-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#filtering-and-saving-filtered-data",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "Filtering and saving filtered data",
    "text": "Filtering and saving filtered data\nLet’s save the filtered data into a file (for future easy loading).\n\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")\n\nThe following code is to read an RDS file (i.e. the saved filtered (by SG) file).\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html",
    "title": "Hands-on Exercise 7c: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, we will be able to use appropriate functions of tmap and tidyverse to plot analytical maps by\n\nImporting geospatial data in RDS format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 7c: Analytical Mapping",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#data-import",
    "title": "Hands-on Exercise 7c: Analytical Mapping",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data set called called NGA_wp.rds, is a polygon feature data.frame providing information on water point of Nigeria at the LGA level.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#percentile-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#percentile-map",
    "title": "Hands-on Exercise 7c: Analytical Mapping",
    "section": "5.1 Percentile Map",
    "text": "5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\nData PreparationCreating get.var functionA percentile mapping functionRun the code!\n\n\nStep 1: Exclude records with NA by using the code chunk below.\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle = NA, mtitle = \"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \n                   \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nWe can use additional arguments such as the title, legend positioning etc to customise various features of the map."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#box-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07c.html#box-map",
    "title": "Hands-on Exercise 7c: Analytical Mapping",
    "section": "5.2 Box map",
    "text": "5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\nCreating boxbreaks functionCreating get.var functionRun the functionBoxmap function\n\n\nThe code chunk below is an R function that creating break points for a box map. The return is a vector with 7 break points compute quartile and fences\n\nboxbreaks &lt;- function(v, IQRmult = 1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + IQRmult * iqr\n  lofence &lt;- qv[2] - IQRmult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\nboxmap &lt;- function(vnam, df, \n                   legtitle = NA,\n                   mtitle = \"Box Map\"){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam, title=legtitle,\n             breaks = bb,\n             palette = \"Blues\",\n             labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colours. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of the aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this exercise, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-import",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nTwo datasets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is geospatial data which consists of the geographical boundary of Singapore at the planning subzone level. The data is based on the URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in CSV format (i.e. respopagesextod2011to2020.csv). This is an aspatial data file. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, its PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",  \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Vanessa\\SMU\\Term 4 - Visual Analytics & Applications\\mvheng\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet’s examine the data.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\") \npopdata\n\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# ℹ 984,646 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-preparation",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "2.3 Data Preparation",
    "text": "2.3 Data Preparation\nBefore a thematic map can be prepared, we are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against the economy active group\n\n\nData wranglingJoining the attribute data and geospatial data\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%   \n  filter(Time == 2020) %&gt;%   \n  group_by(PA, SZ, AG) %&gt;%   \n  summarise(`POP` = sum(`Pop`)) %&gt;% \n  ungroup() %&gt;%  \n  pivot_wider(names_from = AG,\n              values_from = POP) \n\npopdata2020 &lt;- popdata2020 %&gt;% \n  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[14])) %&gt;% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15]))%&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%   mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,    \n         `TOTAL`, `DEPENDENCY`)\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%   \n  mutate_at(.vars = vars(PA, SZ),    \n            .funs = list(toupper)) %&gt;%  \n  filter(`ECONOMY ACTIVE` &gt; 0) \n\n\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,                     \n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.1 Plotting a choropleth map quickly by using qtm()",
    "text": "3.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")  \nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.2 Creating a choropleth map by using tmap’s elements",
    "text": "3.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness in drawing a choropleth map quickly and easily, the disadvantage of qtm() is that it makes the aesthetics of individual layers harder to control. To draw a high-quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +   \n  tm_fill(\"DEPENDENCY\",            \n          style = \"quantile\",          \n          palette = \"Blues\",          \n          title = \"Dependency ratio\") + \n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\", \n            main.title.size = 1.2,        \n            legend.height = 0.45,   \n            legend.width = 0.35,       \n            frame = TRUE) +  \n  tm_borders(alpha = 0.5) +   \n  tm_compass(type=\"8star\", size = 2) + \n  tm_scale_bar() +   \n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics DOS\",    \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will explore how tmap functions are used to plot these elements.\n\nDraw a base mapUsing tm_fill() and tm_border()\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +   \n  tm_polygons()\n\n\n\n\n\nDraw a choropleth map\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, missing values will be shaded in grey.\n\n\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020) +     \n  tm_fill(\"DEPENDENCY\") +   \n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nThe planning subzones are shared according to the respective dependency values.\nThe light-grey border lines have been added to the choropleth map.\nThese are the arguments for tm_borders() to change the asethestic:\n\nalpha = the transparency number between 0 (totally transparent) and 1 (not transparent). The default is 1.\ncol = border colour\nlwd = border line width. The default is 1.\nlty = borderline type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.3 Data classification methods of tmap",
    "text": "3.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nBuilt-in classification methodsCategory break\n\n\nThe code chunk below shows a quantile data classification that used 5 classes and ‘jenks’ style.\n\ntm_shape(mpsz_pop2020)+   \n  tm_fill(\"DEPENDENCY\",      \n          n = 5,          \n          style = \"jenks\") +  \n  tm_borders(alpha = 0.5)\n\n\n\n\nThe code chunk below shows a quantile data classification that used 5 classes and ‘equal’ style.\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(\"DEPENDENCY\",    \n          n = 5,         \n          style = \"equal\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nWarning: Maps Lie!\n\n\n\nThe distribution of quantile data classification using ‘jenks’ method is more evenly distributed than ‘equal’ method.\nHence, when preparing choropleth maps, we should use different classification methods supported by tmap and compare their differences.\nWe should also use similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20) and compare the differences.\n\n\n\n2 classes6 classes10 classes20 classes\n\n\n\ntm_shape(mpsz_pop2020)+  \n  tm_fill(\"DEPENDENCY\",     \n          n = 2,           \n          style = \"jenks\") +  \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_fill(\"DEPENDENCY\",       \n          n = 6,           \n          style = \"jenks\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +  \n  tm_fill(\"DEPENDENCY\",      \n          n = 10,       \n          style = \"jenks\") +  \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +  \n  tm_fill(\"DEPENDENCY\",         \n          n = 20,          \n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nFor our data, it is not suitable to use a big number of classes, as we can see all the 19 classes are for the dependency range from 0 to 1.33 (too granular).\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nLet’s get some descriptive statistics on the variable first before setting the breakpoints. The code chunk below will be used to compute and display the descriptive statistics of the DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nBased on the results above, we set breakpoints at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 1.\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +     \n  tm_fill(\"DEPENDENCY\",             \n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +    \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#colour-scheme",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.4 Colour Scheme",
    "text": "3.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+   \n  tm_fill(\"DEPENDENCY\",            \n          n = 6,                     \n          style = \"quantile\",                    \n          palette = \"Blues\") +    \n  tm_borders(alpha = 0.5)\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",     \n          style = \"quantile\",      \n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#map-layouts",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.5 Map Layouts",
    "text": "3.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include among other objects to be mapped, the title, the scale bar, the compass, margins and aspect ratios.\n\nMap LegendMap styleCartographic Furniture\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +   \n  tm_fill(\"DEPENDENCY\",    \n          style = \"jenks\",     \n          palette = \"Blues\",    \n          legend.hist = TRUE,      \n          legend.is.portrait = TRUE, \n          legend.hist.z = 0.1) +  \n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",       \n            main.title.position = \"center\",  \n            main.title.size = 1,       \n            legend.height = 0.45,          \n            legend.width = 0.35,          \n            legend.outside = FALSE,        \n            legend.position = c(\"right\", \"bottom\"),   \n            frame = FALSE) +   \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020) +  \n  tm_fill(\"DEPENDENCY\",        \n          style = \"quantile\",   \n          palette = \"-Greens\") +  \n  tm_borders(alpha = 0.5) +  \n  tmap_style(\"classic\")\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+  \n  tm_fill(\"DEPENDENCY\",          \n          style = \"quantile\",       \n          palette = \"Blues\",          \n          title = \"No. of persons\") + \n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",             main.title.position = \"center\",  \n            main.title.size = 1.2,          \n            legend.height = 0.45,         \n            legend.width = 0.35,         \n            frame = TRUE) +   \n  tm_borders(alpha = 0.5) +  \n  tm_compass(type=\"8star\", size = 2) + \n  tm_scale_bar(width = 0.15) +   \n  tm_grid(lwd = 0.1, alpha = 0.2) +  \n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics DOS\",  \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.6 Drawing Small Multiple Choropleth Maps",
    "text": "3.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nUse aesthetic arguments tm_fill()Use aesthetic arguments tm_polygons()Using tm_facets()Using tmap_arrange()\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill().\n\ntm_shape(mpsz_pop2020)+  \n  tm_fill(c(\"YOUNG\", \"AGED\"), \n          style = \"equal\",     \n          palette = \"Blues\") + \n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) + \n  tmap_style(\"white\")\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to tm_polygons() with different palette.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),   \n              style = c(\"equal\", \"quantile\"),   \n              palette = list(\"Blues\",\"Greens\")) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\",    \n          style = \"quantile\",   \n          palette = \"Blues\",    \n          thres.poly = 0) +   \n  tm_facets(by=\"REGION_N\",        \n            free.coords=TRUE,        \n            drop.shapes=FALSE) + \n  tm_layout(legend.show = FALSE,         \n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +   \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +   \n  tm_polygons(\"YOUNG\",               \n              style = \"quantile\",     \n              palette = \"Blues\")  \nagedmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\",            \n              style = \"quantile\", \n              palette = \"Blues\")  \ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "3.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "3.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, we can also use a selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +  \n  tm_fill(\"DEPENDENCY\",            \n          style = \"quantile\",       \n          palette = \"Blues\",           \n          legend.hist = TRUE,        \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +   \n  tm_layout(legend.outside = TRUE,    \n            legend.height = 0.45,   \n            legend.width = 5.0,       \n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +   \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#all-about-tmap-package",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "4.1 All about tmap package",
    "text": "4.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "4.2 Geospatial data wrangling",
    "text": "4.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#data-wrangling-1",
    "title": "Hands-on Exercise 7a: Choropleth Mapping with R",
    "section": "4.3 Data wrangling",
    "text": "4.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html",
    "title": "Hands-on Exercise 5d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index.\nParallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, a parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nThis exercise aims to plot static and interactive parallel coordinates plots for visualising and analysing multivariate, numerical data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\nGGally, extends ggplot2 by adding several functions to reduce the complexity of combining geometric objects with transformed data.\nparcoords, package allow users the very well designed and interactive parallel-coordinates chart for d3 with the infrastructure, flexibility, and robustness of htmlwidgets.\nparallelPlot is used to construct a parallel coordinate plot for a data set with classes in last column.\n\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#data-import",
    "title": "Hands-on Exercise 5d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data of World Happines 2018 report will be used. The data set is downloaded from here.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "Hands-on Exercise 5b: Visual Correlation Analysis",
    "section": "",
    "text": "The correlation coefficient is a popular statistic that is used to measure the type and strength of the relationship between two variables. The values of a correlation coefficient range between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficients of the pair comparisons are displayed in a table form known as a correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression, a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram is used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitates perception.\n\nThis exercise aim to plot data visualisation for visualising correlation matrix with R, by creating a correlation matrix using pairs() , plot a corrgram using corrplot and create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5b: Visual Correlation Analysis",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\ncorrplot, an R package which provides a visual exploratory tool on correlation matrix that supports automatic variable reordering to help detect hidden patterns among variables.\n\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#data-import",
    "title": "Hands-on Exercise 5b: Visual Correlation Analysis",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe Wine Quality Data Set of UCI Machine Learning Repository is used which consists of 13 variables and 6497 observations.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "title": "Hands-on Exercise 4d: Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "This exercise aims to gain hands-on experience in plotting funnel plots which are specially designed data visualisations for conducting unbiased comparison between outlets, stores or business entities by\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4d: Funnel Plots for Fair Comparisons",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science processes,\nplotly for creating interactive plot\nFunnelPlotR for creating funnel plot.\nknitr for building static html table.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#data-import",
    "title": "Hands-on Exercise 4d: Funnel Plots for Fair Comparisons",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\ncovid19 \n\n# A tibble: 267 × 7\n   `Sub-district ID` City       District `Sub-district` Positive Recovered Death\n               &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;    &lt;fct&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        3172051003 JAKARTA U… PADEMAN… ANCOL              1776      1691    26\n 2        3173041007 JAKARTA B… TAMBORA  ANGKE              1783      1720    29\n 3        3175041005 JAKARTA T… KRAMAT … BALE KAMBANG       2049      1964    31\n 4        3175031003 JAKARTA T… JATINEG… BALI MESTER         827       797    13\n 5        3175101006 JAKARTA T… CIPAYUNG BAMBU APUS         2866      2792    27\n 6        3174031002 JAKARTA S… MAMPANG… BANGKA             1828      1757    26\n 7        3175051002 JAKARTA T… PASAR R… BARU               2541      2433    37\n 8        3175041004 JAKARTA T… KRAMAT … BATU AMPAR         3608      3445    68\n 9        3171071002 JAKARTA P… TANAH A… BENDUNGAN HIL…     2012      1937    38\n10        3175031002 JAKARTA T… JATINEG… BIDARA CINA        2900      2773    52\n# ℹ 257 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#fair-visual-comparisons-using-funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#fair-visual-comparisons-using-funnelplotr-methods",
    "title": "Hands-on Exercise 4d: Funnel Plots for Fair Comparisons",
    "section": "3.1 Fair Visual Comparisons using FunnelPlotR methods",
    "text": "3.1 Fair Visual Comparisons using FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nBasicMakeover 1Makeover 2\n\n\nThe following basic plot shows a funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for over-dispersion.\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`)\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR” (indirectly standardised ratios). Other options: “PR” for proportions, or “RC” for ratios of counts.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\nThe following funnel plot object has 267 points of which 7 are outliers. Plot is adjusted for over-dispersion.\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05))\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nNote\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nx_range and y_range are used to set the range of x-axis and y-axis\n\n\n\n\n\n\n\nShow the code\nfunnel_plot(\n    numerator = covid19$Death,\n    denominator = covid19$Positive,\n    group = covid19$`Sub-district`,\n    data_type = \"PR\",   \n    x_range = c(0, 6500),  \n    y_range = c(0, 0.05),\n    label = NA,\n    title = \"Cumulative COVID-19 Fatality Rate by \\nCumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n    x_label = \"Cumulative COVID-19 Positive Cases\", \n    y_label = \"Cumulative Fatality Rate\")\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nNote\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#fair-visual-comparisons-using-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#fair-visual-comparisons-using-ggplot2-methods",
    "title": "Hands-on Exercise 4d: Funnel Plots for Fair Comparisons",
    "section": "3.2 Fair Visual Comparisons using ggplot2 methods",
    "text": "3.2 Fair Visual Comparisons using ggplot2 methods\nWe can also build funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\nWe need to create some statistics from the data first by deriving cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\nCompute the upper and lower limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\nStaticInteractive\n\n\n\n\nShow the code\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label= `Sub-district`), alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, y = number.ll999), \n            size = 0.4, \n            colour = \"darkblue\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, y = number.ul999), \n            size = 0.4, \n            colour = \"darkblue\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             linewidth = 0.4, \n             colour = \"darkred\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  labs(title = \"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\",\n       x = \"Cumulative Number of COVID-19 Cases\", \n       y = \"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\")) +\n  annotate(\"text\", x = 100, y = 0.03, label = \"95%\", size = 3, colour = \"red\") + \n  annotate(\"text\", x = 600, y = 0.035, label = \"99%\", size = 3, colour = \"red\")\n\np\n\n\n\n\n\n\n\nUse ggplotly to make the chart interactive.\n\nggplotly(p,tooltip = c(\"label\", \"x\", \"y\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "",
    "text": "This exercise aims to\n\nGain hands-on experience in visual statistical analysis using:ggstatsplot  package to create visual graphics with rich statistical information.\nVisualise model diagnostics and model parameters using performance and parameters packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science processes,\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests in the information-rich plots themselves.\n\n\npacman::p_load(tidyverse, ggstatsplot)\npacman::p_load(readxl, performance, parameters, see)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#data-import",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe following datasets are used for this exercise.\n\nToyota Corolla case study will be used. The purpose of the study is to build a model to discover factors affecting the prices of used cars by taking into consideration a set of explanatory variables.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nexam_data\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-sample-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-sample-test",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "3.1 One-sample test",
    "text": "3.1 One-sample test\ngghistostats() produces a histogram with statistical details from a one-sample test included in the plot as a subtitle."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#what-is-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#what-is-bayes-factor",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "What is Bayes Factor?",
    "text": "What is Bayes Factor?\n\nA Bayes factor is the ratio of the likelihood of an alternate hypothesis (BF10) to the likelihood of the null hypothesis (BF01). It can be interpreted as a measure of the strength of evidence in favour of one theory among two competing theories.\nIt can be any positive number.\nIt gives us a way to evaluate the data in favour of a null hypothesis and to use external information to do so. It tells us what the weight of the evidence is in favour of a given hypothesis.\nThe Schwarz criterion is one of the easiest ways to calculate a rough approximation of the Bayes Factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#two-sample-mean-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#two-sample-mean-test",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "3.2 Two-sample mean test",
    "text": "3.2 Two-sample mean test\nggbetweenstats() is used to build a visual for a two-sample mean test of Maths scores by gender as shown below.\n\n\nShow the code\nggbetweenstats(data = exam_data,\n              x = GENDER, \n              y = MATHS,\n              type = \"np\",\n              messages = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-way-anova-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-way-anova-test",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "3.3 One-way ANOVA Test",
    "text": "3.3 One-way ANOVA Test\nggbetweenstats() is used to build a visual for a one-way ANOVA test on English scores by race as shown below.\n\n\nShow the code\nggbetweenstats(data = exam_data,\n            x = RACE, \n            y = ENGLISH,\n            type = \"p\",\n            mean.ci = TRUE, \n            pairwise.comparisons = TRUE, \n            pairwise.display = \"s\", \n            p.adjust.method = \"fdr\",\n            messages = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor pairwise.display options:\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-correlation",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-correlation",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "3.4 Significant Test of Correlation",
    "text": "3.4 Significant Test of Correlation\nggscatterstats() is used to build a visual for a significant Test of Correlation between Maths scores and English scores as shown below.\n\n\nShow the code\nggscatterstats(data = exam_data,\n                x = MATHS,\n                y = ENGLISH,\n                marginal = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-association-dependence",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-association-dependence",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "3.5 Significant Test of Association (Dependence)",
    "text": "3.5 Significant Test of Association (Dependence)\nThe Maths scores are binned into a 4-class variable by using cut() and then ggbarstats() is used to build a visual for the significant Test of Association.\n\n\nShow the code\nexam_math &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = cut(MATHS, breaks = c(0,60,75,85,100)))\n\nggbarstats(exam_math, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#multiple-regression-model",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#multiple-regression-model",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.1 Multiple Regression Model",
    "text": "4.1 Multiple Regression Model\nThe following is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-for-multicollinearity",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-for-multicollinearity",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.2 Model Diagnostic - check for multicollinearity",
    "text": "4.2 Model Diagnostic - check for multicollinearity\nWe use check_collinearity() of performance package to check for multicollinearity.\n\ncheck_c &lt;- check_collinearity(model)\ncheck_c\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nplot(check_c)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-normality-assumption",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-normality-assumption",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.3 Model Diagnostic - check normality assumption",
    "text": "4.3 Model Diagnostic - check normality assumption\nWe use check_normality() of performance package to check normality assumption.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\ncheck_n &lt;- check_normality(model1)\nplot(check_n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-homogeneity-of-variances-assumption",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---check-homogeneity-of-variances-assumption",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.4 Model Diagnostic - Check homogeneity of variances assumption",
    "text": "4.4 Model Diagnostic - Check homogeneity of variances assumption\nWe use check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---complete-check",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#model-diagnostic---complete-check",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.5 Model Diagnostic - Complete check",
    "text": "4.5 Model Diagnostic - Complete check\nWe can also perform the complete model diagnostic by using check_model().\n\ncheck_model(model1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-regression-parameters",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-regression-parameters",
    "title": "Hands-on Exercise 4b: Visual Statistical Analysis",
    "section": "4.6 Visualising Regression Parameters",
    "text": "4.6 Visualising Regression Parameters\n\nplot()ggcoefstats()\n\n\nWe use plot() of see package and parameters() of parameters package to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\nWe use ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "",
    "text": "This exercise explores two relatively new statistical graphic methods for visualising distribution, namely the ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science processes,\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots, and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(ggdist, ggridges, ggthemes, \n               colorspace, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#data-import",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe following dataset is used for this exercise.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#plotting-ridgeline-graph-using-ggridges-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#plotting-ridgeline-graph-using-ggridges-method",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "3.1 Plotting ridgeline graph using** ggridges method",
    "text": "3.1 Plotting ridgeline graph using** ggridges method\nThere are several ways to plot a ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots:\n\ngeom_ridgeline() takes height values directly to draw the ridgelines\ngeom_density_ridges()estimates data densities and then draws those using ridgelines\n\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\n\nShow the code\nggplot(exam_data, \n       aes(x = ENGLISH, y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nTo plot a density ridges chart, we need to have one continuous variable and one categorical variable.\nThe density ridges chart is a smooth curve (interpolated from actual points), not the actual points. Hence, do not add interactivity to this chart.\nUse this chart to show the shape of the distribution (skewness/spread of the distribution or resemble normal distribution)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#varying-fill-colours-along-the-x-axis",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#varying-fill-colours-along-the-x-axis",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "3.2 Varying fill colours along the x-axis",
    "text": "3.2 Varying fill colours along the x-axis\nLet’s change the area under a ridgeline filled with colours that vary in some form along the x-axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colours.\nHowever, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\noption is a character string indicating the colour map option to use. Eight options are available: “magma” (or “A”) “inferno” (or “B”) “plasma” (or “C”) “viridis” (or “D”) “cividis” (or “E”) “rocket” (or “F”) “mako” (or “G”) “turbo” (or “H”)\n\n\nShow the code\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(scale = 3,\n                            rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Score\",\n                       option = \"C\") +\n  scale_x_continuous(name = \"English grades\",\n                  expand = c(0, 0)) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#mapping-the-probabilities-directly-onto-colour",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#mapping-the-probabilities-directly-onto-colour",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "3.3 Mapping the probabilities directly onto colour",
    "text": "3.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nThe following is plotted by mapping the probabilities calculated by using stat(ecdf) which represents the empirical cumulative density function for the distribution of English scores.\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5 - after_stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Probability\",\n                       direction = -1) +\n  scale_x_continuous(name = \"English grades\",\n                  expand = c(0, 0)) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou would be able to compare the 50th percentile easily as well as those 10th and 90th percentile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#ridgeline-plots-with-quantile-lines",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-on Exercise 4a: Visualing Distributions",
    "section": "3.4 Ridgeline plots with quantile lines",
    "text": "3.4 Ridgeline plots with quantile lines\n\nQuartilesCut-points\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated after_stat(quantile) aesthetic as shown in the figure below.\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(after_stat(quantile)))) +\n  stat_density_ridges(\n          geom = \"density_ridges_gradient\",\n          calc_ecdf = TRUE, \n          quantiles = 4,\n          quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  scale_x_continuous(name = \"English grades\",\n                  expand = c(0, 0)) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nWe can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\n\nShow the code\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n          geom = \"density_ridges_gradient\",\n          calc_ecdf = TRUE, \n          quantiles = c(0.025, 0.975)) +\n  scale_fill_manual(\n      name = \"Probability\",\n      values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n      labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\"))+\n  scale_x_continuous(name = \"English grades\",\n                  expand = c(0, 0)) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c: Visualing Uncertainty",
    "section": "",
    "text": "This exercise aims to gain hands-on experience on creating statistical graphics for visualising uncertainty by:\n\nplotting statistics error bars by using ggplot2,\nplotting interactive error bars by combining ggplot2, plotly and DT,\ncreating advanced by using ggdist, and\ncreating hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4c: Visualing Uncertainty",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science processes,\nplotly for creating interactive plot\ngganimate for creating animation plot\nDT for displaying interactive html table\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering)\n\n\n#devtools::install_github(\"wilkelab/ungeviz\")\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#data-import",
    "title": "Hands-on Exercise 4c: Visualing Uncertainty",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe following dataset is used for this exercise.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nexam_data\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4c: Visualing Uncertainty",
    "section": "3.1 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3.1 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\nHTML tableError BarsConfidence IntervalInteractive Errorbar\n\n\nLet’s plot error bars of maths scores by race by using data provided in exam_data tibble data frame and then display the information in an HTML table format.\n\n\nShow the code\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(n = n(),\n          mean = mean(MATHS),\n          sd = sd(MATHS)) %&gt;%\n  mutate(se = sd/sqrt(n-1))\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive the standard error of Maths by RACE, and the output is saved as a tibble data table called my_sum.\n\n\n\n\n\nLet’s plot the standard error bars of mean maths score by race as shown below.\n\n\nShow the code\nggplot(my_sum) +\n  geom_errorbar(aes(x = RACE, \n                  ymin = mean - se, \n                  ymax = mean + se), \n              width=0.2, \n              colour=\"black\", \n              alpha=0.9, \n              size=0.5) +\n  geom_point(aes(x = RACE, y = mean), \n           stat = \"identity\", \n           color = \"red\",\n           size = 1.5,\n           alpha = 1) +\n  ggtitle(\"Standard error of mean maths scores by race\")\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFor geom_point(), it is important to indicate stat = “identity”.\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\n\nShow the code\nggplot(my_sum) +\n  geom_errorbar(\n            aes(x=reorder(RACE, -mean), \n                ymin = mean - 1.96*se, \n                ymax = mean + 1.96*se), \n            width=0.2, \n            colour=\"black\", \n            alpha=0.9, \n            size=0.5) +\n  geom_point(aes\n           (x=RACE, y=mean), \n           stat = \"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(title = \"95% confidence interval of mean maths scores by race\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\n\n\n\n\n\nLet’s plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\n\nShow the code\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x = reorder(RACE, -mean),\n                     ymin = mean - 2.58*se, \n                     ymax = mean + 2.58*se), \n                     width = 0.2, \n                     colour = \"black\", \n                     alpha = 0.9, \n                     size = 0.5) +\n           geom_point(aes(x = RACE, y = mean, \n                 text = paste(\"Race:\", `RACE`, \n                              \"&lt;br&gt;N:\", `n`,\n                              \"&lt;br&gt;Avg. Scores:\", round(mean, 2),\n                              \"&lt;br&gt;95% CI:[\", \n                              round((mean - 2.58*se), 2), \",\",\n                              round((mean + 2.58*se), 2),\"]\")),\n                 stat=\"identity\", \n                 color=\"red\", \n                 size = 1.5, \n                 alpha=1) + \n            labs(x = \"Race\", y = \"Average Scores\",\n                 title = \"99% Confidence interval of average /&lt;br&gt;maths scores by race\")) + \n            theme_minimal() + \n            theme(axis.text.x = element_text(\n                  angle = 45, vjust = 0.5, hjust=1)), tooltip = \"text\"), \n       \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4c: Visualing Uncertainty",
    "section": "3.2 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "3.2 Visualizing the uncertainty of point estimates: ggdist methods\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nstat_pointinterval()stat_gradientinterval()HOP\n\n\nstat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nShow the code\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(point_interval = \"median_qi\",\n                show.legend = FALSE) +\n  labs( title = \"Visualising confidence intervals of mean Maths scores\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nstat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nShow the code\nggplot(exam_data, aes(x = RACE, y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE) +                        \n  labs(title = \"Visualising confidence intervals of mean Maths scores\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\nLet’ plot using Hypothetical Outcome Plots (HOPs) where users can visualize a set of draws from a distribution, where each draw is shown as a new plot in either a small multiples or animated form.\n\n\nShow the code\nggplot(data = exam_data, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 0.5) +\n  geom_hpline(data = sampler(25, group = RACE), \n              height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  labs(x = \"Race\") +\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Hands-on Exercise 5a: Creating Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nWe will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5a: Creating Ternary Plot with R",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\nggtern, a ggplot extension, specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#data-import",
    "title": "Hands-on Exercise 5a: Creating Ternary Plot with R",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used.\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#preparing-the-data",
    "title": "Hands-on Exercise 5a: Creating Ternary Plot with R",
    "section": "2.3 Preparing the Data",
    "text": "2.3 Preparing the Data\nThe population data needs to be presented in a different way.\nLet’s use the mutate() function of dplyr package to derive three new measures, namely:\n\nyoung: 0 - 24 years old\nactive: 25 - 64 years old\nold: 65 years old and above\n\nThe data is filtered for 2018.\n\nagpop_mutated &lt;- pop_data %&gt;%\n# change year column from numeric to character\n  mutate(`Year` = as.character(Year))%&gt;%\n#spread the age column to multiple age-category columns\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, by placing variables in the columns and observations (or records) in rows and colouring the cells within the table.\nHeatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and detecting if any correlations exist in-between them.\nThis exercise aims to plot static and interactive heatmaps for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\nSeriation: The package provides several visualizations (grid and ggplot2) to reveal structural information, including permuted image plots, reordered heatmaps, Bertin plots, clustering visualizations like dissimilarity plots, and visual assessment of cluster tendency plots (VAT and iVAT).\ndendextend: provides general functions for handling tree-like structures in R.\n\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#data-import",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data of World Happines 2018 report will be used. The data set is downloaded from here.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#preparing-the-data",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2.3 Preparing the Data",
    "text": "2.3 Preparing the Data\nLet us change the rows by country name instead of row number. And then convert this to a data matrix to make our heatmap.\n\nrow.names(wh) &lt;- wh$Country \nwh1 &lt;- dplyr::select(wh, c(3, 7:12))  \nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#normalising-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#normalising-the-data",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.1 Normalising the data",
    "text": "4.1 Normalising the data\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalize and percentize.\n\nScaleNormalizePercentize\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation. The scale argument supports column and row scaling.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nWhen variables in the data come from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank. This is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#clustering-algorithm",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.2 Clustering algorithm",
    "text": "4.2 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithms. The main arguments provided are:\n\ndistfun: to compute the distance (dissimilarity) between both rows and columns. Default is “dist”. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Default is”hclust”.\ndist_method: default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust: default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManualStatistical\n\n\nThis heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of clusters the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the highest optimum value.\nNext, find_k() is used to determine the optimal number of clusters.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFrom the graph, the optimal number of clusters, k is 3.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#seriation",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.3 Seriation",
    "text": "4.3 Seriation\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\n\nOLOGWMeanNone\n\n\nOptimal Leaf Ordering (OLO), starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around to minimize the sum of dissimilarities between adjacent leaves.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\n\n“GW” (Gruvaeus and Wainer) which aims for the same goal as OLO but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\n\n“mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\n\n“none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.4 Working with colour palettes",
    "text": "4.4 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. However, we can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap. Example of using Blues colour palette of rColorBrewer.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#finishing-touch",
    "title": "Hands-on Exercise 5c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.5 Finishing touch",
    "text": "4.5 Finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nShow the code\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html",
    "title": "Hands-on Exercise 5e: Treemap Visualisation with R",
    "section": "",
    "text": "A Treemap displays hierarchical data as a set of nested rectangles. Each group is represented by a rectangle, whose area is proportional to its value. In this exercise, we will learn how to manipulate transaction data into a treemap structure by using selected functions provided in dplyr package. Then, we will learn how to plot static treemap by using treemap package. Finally, we will learn how to design an interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5e: Treemap Visualisation with R",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used.\n\ntreemap is a space-filling visualization of hierarchical structures. This function offers great flexibility to draw treemaps.\ntreemapify draws the treemap without the help of the ggplot2 geoms, or for some edge cases such as creating interactive treemaps with ‘RShiny’.\nd3treeRis the primary function for creating interactive d3.js treemaps from various data types in R.\n\n\ninstall.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\npacman::p_load(treemap, treemapify, d3treeR, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#data-import",
    "title": "Hands-on Exercise 5e: Treemap Visualisation with R",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data of private property transaction records in 2018 is extracted from REALIS portal of Urban Redevelopment Authority (URA).\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#preparing-the-data",
    "title": "Hands-on Exercise 5e: Treemap Visualisation with R",
    "section": "2.3 Preparing the Data",
    "text": "2.3 Preparing the Data\nThe data frame realis2018 is in transaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. Hence, we will need perform the following steps to manipulate and prepare a data frame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nWe will use group_by() and summarize() of dplyr package.\ngroup_by()breaks down a data frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nLet us look at how to group summaries without pipe and with pipe (%&gt;%) .\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\nWithout pipeWith pipe\n\n\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\nThe argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\n\nThis is a more efficient method.\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people.\nLike choropleth maps, we can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed ones are called proportional symbols, where the area of the symbols is proportional to the values of the attribute being mapped.\nIn this exercise, we will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\nIn this exercise, we will do the following tasks:\n\nTo import an aspatial data file into R.\nTo convert it into a simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly created simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#data-import",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data set used for this hands-on exercise is called SGPools_svy21. The data is in CSV file format.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\nhead(sgpools, 5)\n\n# A tibble: 5 × 7\n  NAME            ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n  &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n1 Livewire (Mari… 2 Bayf…    18972 30842. 29599. Branch                        5\n2 Livewire (Reso… 26 Sen…    98138 26704. 26526. Branch                       11\n3 SportsBuzz (Kr… Lotus …   738078 20118. 44888. Branch                        0\n4 SportsBuzz (Po… 1 Sele…   188306 29777. 31382. Branch                       44\n5 Prime Serangoo… Blk 54…   552542 32239. 39519. Branch                        0\n\n\nThe data consists seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\n\n\nNote\n\n\n\nsgpools data in tibble data frame and not the common R data frame.\n\n\n\n2.2.1 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\n\ncoords argument: states the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument: states the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. For other country’s epsg code, we can check out here epsg.io.\n\n\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nWe can see that the data table of sgpools_sf has a new column called geometry."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#all-about-tmap-package",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "4.1 All about tmap package",
    "text": "4.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "4.2 Geospatial data wrangling",
    "text": "4.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07b.html#data-wrangling",
    "title": "Hands-on Exercise 7b: Visualising Geospatial Point Data",
    "section": "4.3 Data wrangling",
    "text": "4.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "",
    "text": "In this exercise, we will learn how to model, analyse and visualise network data using R:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "2.1 Installing and loading the packages",
    "text": "2.1 Installing and loading the packages\nFor this exercise, 4 network data modeling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Besides these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangle time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-import",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nThe data sets used is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\nglimpse(GAStech_nodes)\n\nRows: 54\nColumns: 4\n$ id         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 44, 45, 46, 8, 9, 10, 11, 12, 13, 14, …\n$ label      &lt;chr&gt; \"Mat.Bramar\", \"Anda.Ribera\", \"Rachel.Pantanal\", \"Linda.Lago…\n$ Department &lt;chr&gt; \"Administration\", \"Administration\", \"Administration\", \"Admi…\n$ Title      &lt;chr&gt; \"Assistant to CEO\", \"Assistant to CFO\", \"Assistant to CIO\",…\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-time",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-time",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "2.3 Wrangling time",
    "text": "2.3 Wrangling time\nFrom the above, we can notice that SentDate should not be in character type. The code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if the label is TRUE. The argument abbr is FALSE keep the day spells in full, i.e. Monday. The function will create a new column in the dataframe i.e. Weekday and the output of wday() will be saved in this newly created field. The values in the Weekday field are in ordinal scale."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-attributes",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "2.4 Wrangling attributes",
    "text": "2.4 Wrangling attributes\nA close examination of GAStech_edges dataframe reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nWe only filter by work-related in the mainSubject and count the number of rows in each group.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-tbl_graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-tbl_graph-object",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "3.1 The tbl_graph object",
    "text": "3.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame\ndata.frame, list, matrix from base\nigraph from igraph\nnetwork from network\ndendrogram and hclust from stats\nNode from data.tree\nphylo and evonet from ape\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-dplyr-verbs",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-dplyr-verbs",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "3.2 The dplyr verbs",
    "text": "3.2 The dplyr verbs\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#using-tbl_graph-to-build-tidygraph-data-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#using-tbl_graph-to-build-tidygraph-data-model",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "3.3 Using tbl_graph() to build tidygraph data model",
    "text": "3.3 Using tbl_graph() to build tidygraph data model\nIn this section, you will use tbl_graph() of tidygraph package to build a tidygraph’s network graph dataframe.\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nGAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-active-object",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "3.4 Changing the active object",
    "text": "3.4 Changing the active object\nThe nodes tibble data frame is activated by default, but we can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-centrality-indices",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-centrality-indices",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "6.1 Computing centrality indices",
    "text": "6.1 Computing centrality indices\nCentrality measures are a collection of statistical indices used to describe the relative importance of the actors are in a network. There are four well-known centrality measures, namely: degree, betweenness, closeness, and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measures here.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe algorithm used is the centrality_betweenness() of tidygraph."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-network-metrics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-network-metrics",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "6.2 Visualising network metrics",
    "text": "6.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onwards, tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph to use them in a plot.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-community",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-community",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data",
    "section": "6.3 Visualising Community",
    "text": "6.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it.\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: Tableau Hands-on Part 1",
    "section": "",
    "text": "In this exercise, we have some hands-on on Tableau.\nWe have learned to plot lines and bar charts together by region and order date.\nWe used colour mark card to differentiate profit and loss.\n\nThis visualisation is published in Tableau Public which you can find it here."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4: Recap on interactivity",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse, \n               readxl, gifski,gapminder, gganimate)\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-1",
    "title": "In-class Exercise 4: Recap on interactivity",
    "section": "Exercise 1:",
    "text": "Exercise 1:\nCombining data_id and tooltip together\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(data_id = CLASS, \n                                 tooltip = ID),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-2",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-2",
    "title": "In-class Exercise 4: Recap on interactivity",
    "section": "Exercise 2:",
    "text": "Exercise 2:\nShow tooltip of Maths and English score in Coordinated Multiple Views.\n\n\nShow the code\ntooltip &lt;- c(paste0(\"Name = \", exam_data$ID, \n                    \"\\nMath = \", exam_data$MATHS,\n                    \"\\nEnglish = \", exam_data$ENGLISH))\n             \np1 &lt;- ggplot(data = exam_data,aes(x = MATHS)) +\n      geom_dotplot_interactive(aes(tooltip= tooltip, data_id = ID),\n                              stackgroups = TRUE,\n                              binwidth = 1,\n                              method = \"histodot\") +\n      coord_cartesian(xlim = c(0,100)) +\n      scale_y_continuous(NULL, breaks = NULL) +\n      theme_classic()\n      \np2 &lt;- ggplot(data = exam_data, aes(x = ENGLISH)) +\n      geom_dotplot_interactive(aes(tooltip = ID, data_id = ID),\n                              stackgroups = TRUE,\n                              binwidth = 1,\n                              method = \"histodot\") +\n      coord_cartesian(xlim = c(0,100)) +\n      scale_y_continuous(NULL, breaks = NULL)+\n      theme_classic()\n\ngirafe(code = print(p1 / p2),\n    width_svg = 6,\n    height_svg = 3.8,\n    options = list(\n    opts_hover(css = \"fill: #202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class_Ex06: Time series charts",
    "section": "",
    "text": "In this exercise, we create time-series charts in Tableau and R."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#line-and-cycle-charts",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#line-and-cycle-charts",
    "title": "In-class_Ex06: Time series charts",
    "section": "1.1. Line and Cycle charts",
    "text": "1.1. Line and Cycle charts\nThe dashboard consists of a line chart to show the air arrivals over the years and a cycle chart to show how the air arrivals change for each month. You can view it here.\n\n\n\n\n\n\n\nNote\n\n\n\nIn order to use only 1 filter for both charts, we have to apply one of the filters to all worksheets using the same data source and then keep one of the filters in the dasboard."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#calendar-map",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#calendar-map",
    "title": "In-class_Ex06: Time series charts",
    "section": "1.2 Calendar map",
    "text": "1.2 Calendar map\nWe can also create a calendar map in Tableau.\nThe timestamp column is used 3 times to create this calendar map.\n\nMonth and Week of timestamp in the columns of the chart\nWeekday of timestamp in the rows of the chart\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is a gap at the end and the start of each month as Tableau is not able to gel them together."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-the-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-the-packages",
    "title": "In-class_Ex06: Time series charts",
    "section": "2.1 Installing the packages",
    "text": "2.1 Installing the packages\nggHoriPlot: create a horizon graph to show highly overlapping time-series.\n\npacman::p_load(tidyverse, ggHoriPlot, ggthemes)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#data-import",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#data-import",
    "title": "In-class_Ex06: Time series charts",
    "section": "2.2 Data import",
    "text": "2.2 Data import\nIn this exercise, Average Retail Prices Of Selected Consumer Items will be used.\nWe need to change the data format from character to Date format.\n\naverp &lt;- read_csv(\"data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#create-horizon-graph",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#create-horizon-graph",
    "title": "In-class_Ex06: Time series charts",
    "section": "2.3 Create horizon graph",
    "text": "2.3 Create horizon graph\n\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6) +\n  facet_grid(`Consumer Items`~.) +\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()) +\n  scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07a.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07a.html",
    "title": "In-class Exercise 7a: Geospatial Analysis using Tableau",
    "section": "",
    "text": "1 Overview\nIn this exercise, we have some more hands-on using geographical data on Tableau.\nWe use the realis 2022-2023 data to analyse the property data.\n\n\n2 Load data\nWe have 8 realis files and we union them in Tableau.\n\n\n\n3 Proportional Map\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are 429 unknown postal codes as they are not available in OpenStreetMap.\n\n\nWe also created a tooltip sheet to show the median unit price for each quarter.\n\n\n\n4 Choropleth\nWe use the Planning Area in the map, hence we need to change it to a geographic role using State.\n\n\n\n5 Treemap"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "",
    "text": "OECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Ministers for Education from Singapore also started an “every school a good school” slogan. However, the general public strongly believes that there are disparities, especially between elite schools and neighborhood schools, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status, and between immigrant and non-immigrant families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-r-packages",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "1.1 Installing R packages",
    "text": "1.1 Installing R packages\nThe code below uses p_load() of the Pacman package to check if all the required packages are installed on the laptop. If they are, then they will be launched into the R environment.\n\npacman::p_load(tidyverse, haven, dplyr, ggthemes, patchwork,\n               ggdist, plyr, ggpubr, ggridges, colorspace, reshape2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-pisa-data",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "1.2 Importing PISA data",
    "text": "1.2 Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into the R environment. Note that the code in this segment has the evaluation flag set to FALSE as the data file is big and we do not use it to reload this data again.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\nAs our task is focused on Singapore students, let’s filter the data by CNT = SGP. The data is then saved into another RDS file for easy loading of Singapore data later.\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-singapore-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-singapore-pisa-data",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "1.3 Summary Statistics of Singapore PISA data",
    "text": "1.3 Summary Statistics of Singapore PISA data\nLet’s read the SG data and do some explorations\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\nhead(stu_qqq_SG, 5)\n\n# A tibble: 5 × 1,279\n  CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n# ℹ 1,269 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;dbl&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;,\n#   ST250D07JA &lt;chr&gt;, ST251Q01JA &lt;dbl&gt;, ST251Q02JA &lt;dbl&gt;, ST251Q03JA &lt;dbl&gt;, …\n\n\n\nn_distinct(stu_qqq_SG$CNTSCHID)\n\n[1] 164\n\n\n\nWhat we know about the data:\n\nThere are 1279 columns with 6606 records.\nStudents are randomly picked from all 149 secondary schools and 15 private schools (total 164)\nThere are 10 plausible values for each subject (Maths, Reading, Science)\nStudents are classified into 3 immigrant statuses: Native, 1st generation and 2nd generation\nEconomic, Social and cultural status (ESCS) is calculated based on 3 indicators (highest parental occupation status, HISEI, highest education of parents in years, PAREDINT, and home possessions, HOMEPOS)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#changing-data-types-of-some-columns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#changing-data-types-of-some-columns",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "2.1 Changing data types of some columns",
    "text": "2.1 Changing data types of some columns\nSome of the data types are not correct. For example, immigrant status (IMMIG), gender (ST004D01T), school ID (CNTSCHID), and highest parent education in years (PAREDINT) should be categorical instead of numerical.\n\nstu_qqq_SG$IMMIG[stu_qqq_SG$IMMIG == 1] &lt;- \"Native\"\nstu_qqq_SG$IMMIG[stu_qqq_SG$IMMIG == 2] &lt;- \"1stGen\"\nstu_qqq_SG$IMMIG[stu_qqq_SG$IMMIG == 3] &lt;- \"2ndGen\"\n\nstu_qqq_SG$ST004D01T[stu_qqq_SG$ST004D01T == 1] &lt;- \"Female\"\nstu_qqq_SG$ST004D01T[stu_qqq_SG$ST004D01T == 2] &lt;- \"Male\"\n\nstu_qqq_SG$CNTSCHID &lt;- as.factor(stu_qqq_SG$CNTSCHID)\n\nstu_qqq_SG$PAREDINT &lt;- as.factor(stu_qqq_SG$PAREDINT)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#average-scores-of-each-subject",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#average-scores-of-each-subject",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "2.2 Average scores of each subject",
    "text": "2.2 Average scores of each subject\nLet’s calculate the average of all ten plausible values of each subject and store them in the dataset.\n\nstu_qqq_SG &lt;- stu_qqq_SG %&gt;%\n  mutate(Maths = \n           rowSums(stu_qqq_SG[paste0('PV', c(1:10), \"MATH\")], \n                   na.rm = TRUE)/10) %&gt;% \n  mutate(Reading = \n           rowSums(stu_qqq_SG[paste0('PV', c(1:10), \"READ\")], \n                   na.rm = TRUE)/10) %&gt;% \n  mutate(Science = \n           rowSums(stu_qqq_SG[paste0('PV', c(1:10), \"SCIE\")], \n                   na.rm = TRUE)/10)\n\nLet’s take a look at the spread of each subject’s scores:\n\n# Melt the data first\ntemp_Data &lt;- stu_qqq_SG[, c(\"Maths\", \"Science\", \"Reading\")]\ntemp_Data &lt;- melt(temp_Data, variable.name = \"Subject\")\nggplot(temp_Data, aes(x = value, y = Subject)) +\n  stat_halfeye(aes(fill = Subject), \n               adjust = 0.5,\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(x), 1))) +\n  labs(y = NULL, x = \"scores\",\n       title = \"Distribution of scores\",\n       subtitle = \"Students tend to do better in Maths as compared to Reading and Science\") +\n  theme_economist()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nStudents did better in Maths, followed by Science and then Reading."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#immigrant-vs-non-immigrant-students",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#immigrant-vs-non-immigrant-students",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "2.3 Immigrant vs non-immigrant students",
    "text": "2.3 Immigrant vs non-immigrant students\nLet’s take a look at the proportion of immigrant (1st Generation and 2nd Generation) vs non-immigrant (native) students. Rows with ‘NA’ responses for immigrant status are removed in this plot.\n\nstu_immigrant &lt;- stu_qqq_SG %&gt;% drop_na(IMMIG)\n\nggplot(data = stu_immigrant, aes(x= IMMIG, fill = IMMIG)) +\n  scale_fill_manual(values = c(\"lightgreen\", \"orange\", \"lightblue\")) +\n  geom_bar() + \n  ylim(0, 4700) +\n  geom_text(aes(label = paste0(after_stat(count), \", \", \n      round(after_stat(count)/sum(after_stat(count))*100, 1), \"%\")), \n      stat = \"count\", vjust = -0.5, colour = \"brown\") +\n  labs(x = \"Immigrant status\",\n       title = \"Distribution of immigrant statuses\",\n       subtitle = \"72% of the students are native\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThe majority of the students are native whereas about 27% of the students are 1st or 2nd generation immigrants."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-distribution",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-distribution",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "2.4 Gender distribution",
    "text": "2.4 Gender distribution\nLet’s find out the proportion of female vs male students.\n\npercentage_data &lt;- as.data.frame(table(stu_qqq_SG$ST004D01T))\ncolnames(percentage_data)[1] &lt;- \"Gender\"\npercentage_data &lt;- percentage_data %&gt;%\n  mutate(percentage =  Freq / sum(Freq) * 100)\n\nggplot(percentage_data, aes(x = \"\", y = Freq, fill = Gender)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  theme_void() +\n  scale_fill_manual(values = c(\"#66c2a5\", \"#fc8d62\")) +\n  theme(legend.position = \"right\") +\n  geom_text(aes(label = paste0(sprintf(\"%.1f\", percentage), \"%\")),\n            position = position_stack(vjust = 0.5)) +\n  labs(title = \"Gender distribution\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThe proportion of male and female students are quite similar, with male having slightly over 50%."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#socioeconomic-distribution",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#socioeconomic-distribution",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "2.5 Socioeconomic distribution",
    "text": "2.5 Socioeconomic distribution\nPISA index of economic, social and cultural status (ESCS) is used to distinguish between socio-economically disadvantaged students and socio-economically advantaged students. Socio-economic status is thus a measure of students’ access to family resources (financial capital, social capital, cultural capital and human capital) and the social position of the student’s family/household.\n\nggplot(data = stu_qqq_SG, aes(x = ESCS)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0, point_colour = NA) +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA) +\n  labs(y = NULL,\n       title = \"Distribution of socio-economic index\") +\n  theme_economist()\n\n\n\n\n\nggplot(stu_immigrant, aes(x = IMMIG, y = ESCS)) +\n  stat_halfeye(aes(fill = IMMIG), adjust = 0.5,\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  scale_fill_manual(values = c(\"pink\", \"lightgreen\", \"lightblue\")) +\n  geom_boxplot(width = 0.2) +\n  coord_flip() +\n  theme_economist()+\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(y), 1))) +\n  labs(x =NULL,\n       title = \"Distribution of ESCS by immigrant status\",\n       subtitle = \"Non-native students tends to have a higher ESCS index\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nOn average, the ESCS index for Singaporean students is above 0.\nESCS index is slighty higher for non-native students as compared to the natives."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#immigrant-vs-native-students",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#immigrant-vs-native-students",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "3.1 Immigrant vs Native Students",
    "text": "3.1 Immigrant vs Native Students\nExplore if non-native students did better in any of the subjects as compared to native students.\n\nMathsReadingScience\n\n\n\nmeanScore1 &lt;- ddply(stu_immigrant, \"IMMIG\", summarise, \n                   grp.mean = mean(Maths))\nggplot(stu_immigrant, aes(x = Maths, fill = IMMIG)) +\n  scale_fill_manual(values = c(\"pink\", \"lightgreen\", \"lightblue\")) +\n  geom_density(alpha = 0.5) + \n  geom_vline(data = meanScore1, \n             aes(xintercept = grp.mean, color = IMMIG),\n             linetype = \"dashed\", size = 1) +\n  labs(y = NULL,\n       title = \"Distribution of Maths scores by immigrant status\",\n       subtitle = \"1st Generation students tend to score higher in Maths\") +\n  theme_economist() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\nmeanScore2 &lt;- ddply(stu_immigrant, \"IMMIG\", summarise, \n                   grp.mean = mean(Reading))\nggplot(stu_immigrant, aes(x = Reading, fill = IMMIG)) +\n  scale_fill_manual(values = c(\"pink\", \"lightgreen\", \"lightblue\")) +\n  geom_density(alpha = 0.5) + \n  geom_vline(data = meanScore2, \n             aes(xintercept = grp.mean, color = IMMIG),\n             linetype = \"dashed\", size = 1) +\n  labs(y = NULL,\n       title = \"Distribution of Reading scores by immigrant status\",\n       subtitle = \"1st Generation students tend to score higher in Reading\")+\n  theme_economist() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\nmeanScore3 &lt;- ddply(stu_immigrant, \"IMMIG\", summarise, \n                   grp.mean = mean(Science))\n\nggplot(stu_immigrant, aes(x = Science, fill = IMMIG)) +\n  scale_fill_manual(values = c(\"pink\", \"lightgreen\", \"lightblue\")) +\n  geom_density(alpha = 0.5) + \n  geom_vline(data = meanScore3, \n             aes(xintercept = grp.mean, color = IMMIG),\n             linetype = \"dashed\", size = 1) +\n  labs(y = NULL,\n       title = \"Distribution of Science scores by immigrant status\",\n       subtitle = \"1st Generation students tend to score higher in Science\")+\n  theme_economist() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFrom the graphs above, 1stGen students did better in all 3 subjects as compared to 2ndGen and native students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-between-anxiety-in-maths-and-maths-performance",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-between-anxiety-in-maths-and-maths-performance",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "3.2 Correlation between anxiety in Maths and Maths performance",
    "text": "3.2 Correlation between anxiety in Maths and Maths performance\nResearch has shown that anxiety in students affects their performances in examinations or tests, especially in Maths. Let’s plot a scatter chart to visualise this relationship.\n\nggplot(data = stu_qqq_SG, aes(x = Maths, y = ANXMAT)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth = 0.5) +\n  stat_cor(label.x.npc=\"left\", hjust = 0.1, \n           p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\") +\n  theme_economist() +\n  labs(y = \"Math Anxiety Index\",\n       title = \"Anxiety index vs Math scores\",\n       subtitle = \"Students with high anxiety index tend to do poorer in Maths\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFrom the scatter plot above, we can see that there is a slight negative correlation (r = -0.31) between the anxiety index and Maths scores. This means that students with anxiety (index &gt; 0) tend to do poorer in Maths."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-performance-variations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-performance-variations",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "3.3 Gender Performance Variations",
    "text": "3.3 Gender Performance Variations\nLet’s see how female versus male students perform in the 3 subjects.\n\nMathsReadingScience\n\n\n\nggplot(stu_qqq_SG, aes(x = ST004D01T, y = Maths)) +\n  stat_halfeye(adjust = 0.5, aes(fill = ST004D01T),\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_manual(name = \"Gender\", values = c(\"#66c2a5\", \"#fc8d62\")) +\n  coord_flip() +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(y), 1))) +\n  theme_economist()+\n  labs(x = NULL,\n       title = \"Distribution of Maths scores by Gender\",\n       subtitle = \"Male students tend to do better in Maths than female students\") +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\nggplot(stu_qqq_SG, aes(x = ST004D01T, y = Reading)) +\n  stat_halfeye(adjust = 0.5, aes(fill = ST004D01T),\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_manual(name = \"Gender\", values = c(\"#66c2a5\", \"#fc8d62\")) +\n  coord_flip() +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(y), 1))) +\n  theme_economist()+\n  labs(x = NULL,\n       title = \"Distribution of Reading scores by Gender\",\n       subtitle = \"Female students tend to do better in Reading than male students\") +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\nggplot(stu_qqq_SG, aes(x = ST004D01T, y = Science)) +\n  stat_halfeye(adjust = 0.5, aes(fill = ST004D01T),\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_manual(name = \"Gender\", values = c(\"#66c2a5\", \"#fc8d62\")) +\n  coord_flip() +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(y), 1))) +\n  theme_economist()+\n  labs(x = NULL,\n       title = \"Distribution of Science scores by Gender\",\n       subtitle = \"Male students tend to do better in Science than female students\") +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nMale students seem to perform better in Maths as compared to female students. However, female students did better in Reading than male students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#socio-economic-status-escs-affects-students-performance",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#socio-economic-status-escs-affects-students-performance",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "3.4 Socio-Economic status (ESCS) affects students’ performance",
    "text": "3.4 Socio-Economic status (ESCS) affects students’ performance\nLet’s see how socio-economic status may affect students performance in the 3 subjects.\n\nESCS indexHISEIPAREDINTHOMEPOS\n\n\n\np1 &lt;- ggplot(data = stu_qqq_SG, aes(x = Maths, y = ESCS)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\") \np2 &lt;- ggplot(data = stu_qqq_SG, aes(x = Reading, y = ESCS)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\")\np3 &lt;- ggplot(data = stu_qqq_SG, aes(x = Science, y = ESCS)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\") \n\n(p1 +theme_economist() | \n    p2 + theme_economist() |\n    p3 + theme_economist()) +\n  plot_annotation(\"ESCS index vs subject scores\")\n\n\n\n\n\n\n\nggplot(data = stu_qqq_SG, aes(x = Maths, y = HISEI)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\") +\n  labs(title = \"Highest Parent Occupation Status vs Maths scores\",\n       subtitle = \"Students with high HISEI index tend to do better in Maths\") +\n  theme_economist()\n\n\n\n\n\n\nPAREDINT should be a categorical data, hence let’s convert it to categorical.\n\nggplot(stu_qqq_SG, aes(x = PAREDINT, y = Maths)) +\n  stat_halfeye(adjust = 0.5,\n               justification = 0.1,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.2) +\n  coord_flip() +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, \n               size = 3, color = \"darkred\", \n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun.y = mean, colour=\"darkred\", \n               geom = \"text\", show_guide = FALSE, \n               vjust = -0.7, aes( label=round(after_stat(y), 1))) +\n  theme_economist()+\n  labs(title = \"Distribution of Maths score by PARENDINT index\",\n       subtitle = \"Students with high PAREDINT index tend to do better in Maths\") \n\n\n\n\n\n\n\nggplot(data = stu_qqq_SG, aes(x = Maths, y = HOMEPOS)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01, color = \"brown\") +\n  labs(title = \"Home-possession index vs Maths scores\",\n       subtitle = \"Students with high HOMEPOS index tend to do better in Maths\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nESCS: These 3 scatter plots consistently show that there is a positive correlation between ESCS index and subject scores with a coefficient of 0.44.\nHISEI: There is a positive correlation (0.34) of HISEI index and Maths score.\nPARENINT: Students whose parent’s highest education in years is high tends to score better in Maths\nHOMEPOS: There is a positive correlation (0.34) of HOMEPOS index and Maths score."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#school-performances",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#school-performances",
    "title": "Take-home Exercise 1: PISA Singapore 2022",
    "section": "3.5 School performances",
    "text": "3.5 School performances\nIt is tough to compare the students’ performance among all 164 schools. Hence, let’s focus on the top 75 percentile and bottom 25 percentile students and identify the top 15 schools with the most number of students.\n\nMathsReadingScience\n\n\n\nquantile75Score &lt;- quantile(stu_qqq_SG$Maths, 0.75)\nMTop75 &lt;- filter(stu_qqq_SG, Maths &gt;= quantile75Score)\nMTop75 &lt;- count(MTop75$CNTSCHID)\nnames(MTop75) &lt;- c(\"SchoolID\", \"StudentCount\")\nMTop75 &lt;- MTop75 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\nMTop75$SchoolID &lt;- factor (MTop75$SchoolID, \n                           levels = MTop75$SchoolID[order (MTop75$StudentCount, decreasing = FALSE)])\n\nquantile25Score &lt;- quantile(stu_qqq_SG$Maths, 0.25)\nMBottom25 &lt;- filter(stu_qqq_SG, Maths &lt;= quantile25Score)\nMBottom25 &lt;- count(MBottom25$CNTSCHID)\nnames(MBottom25) &lt;- c(\"SchoolID\", \"StudentCount\")\nMBottom25 &lt;- MBottom25 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\n\nMBottom25$SchoolID &lt;- factor (MBottom25$SchoolID, \n                              levels = MBottom25$SchoolID[order (MBottom25$StudentCount, decreasing = FALSE)])\n\np1 &lt;- ggplot(MTop75, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring above 75 percentile in Maths\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, face = \"bold\", hjust = 1)) + \n  theme(axis.text = element_text(size = 7))\n  \np2 &lt;- ggplot(MBottom25, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring below 25 percentile in Maths\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, face = \"bold\", hjust = 1)) + \n  theme(axis.text = element_text(size = 7))\n\n(p1 / p2) \n\n\n\n\n\n\n\nquantile75Score &lt;- quantile(stu_qqq_SG$Reading, 0.75)\nRTop75 &lt;- filter(stu_qqq_SG, Reading &gt;= quantile75Score)\nRTop75 &lt;- count(RTop75$CNTSCHID)\nnames(RTop75) &lt;- c(\"SchoolID\", \"StudentCount\")\nRTop75 &lt;- RTop75 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\n\nRTop75$SchoolID &lt;- factor (RTop75$SchoolID, \n                           levels = RTop75$SchoolID[order (RTop75$StudentCount, decreasing = FALSE)])\n\nquantile25Score &lt;- quantile(stu_qqq_SG$Reading, 0.25)\nRBottom25 &lt;- filter(stu_qqq_SG, Reading &lt;= quantile25Score)\nRBottom25 &lt;- count(RBottom25$CNTSCHID)\nnames(RBottom25) &lt;- c(\"SchoolID\", \"StudentCount\")\nRBottom25 &lt;- RBottom25 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\n\nRBottom25$SchoolID &lt;- factor (RBottom25$SchoolID, \n                              levels = RBottom25$SchoolID[order (RBottom25$StudentCount, decreasing = FALSE)])\n\np1 &lt;- ggplot(RTop75, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring above 75 percentile in Reading\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, \n                                  face = \"bold\", hjust = 1)) + \n  theme(axis.text = element_text(size = 7))\n  \np2 &lt;- ggplot(RBottom25, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring below 25 percentile in Reading\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, \n                                  face = \"bold\", hjust = 1)) +\n  theme(axis.text = element_text(size = 7))\n\n(p1 / p2)\n\n\n\n\n\n\n\nquantile75Score &lt;- quantile(stu_qqq_SG$Science, 0.75)\nSTop75 &lt;- filter(stu_qqq_SG, Science &gt;= quantile75Score)\nSTop75 &lt;- count(STop75$CNTSCHID)\nnames(STop75) &lt;- c(\"SchoolID\", \"StudentCount\")\nSTop75 &lt;- STop75 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\n\nSTop75$SchoolID &lt;- factor (STop75$SchoolID, \n                           levels = STop75$SchoolID[order (STop75$StudentCount, decreasing = FALSE)])\n\nquantile25Score &lt;- quantile(stu_qqq_SG$Science, 0.25)\nSBottom25 &lt;- filter(stu_qqq_SG, Science &lt;= quantile25Score)\nSBottom25 &lt;- count(SBottom25$CNTSCHID)\nnames(SBottom25) &lt;- c(\"SchoolID\", \"StudentCount\")\nSBottom25 &lt;- SBottom25 %&gt;% \n  arrange(desc(StudentCount)) %&gt;% \n  slice_head(n = 10)\n\nSBottom25$SchoolID &lt;- factor (SBottom25$SchoolID, \n                              levels = SBottom25$SchoolID[order (SBottom25$StudentCount, decreasing = FALSE)])\n\np1 &lt;- ggplot(STop75, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring above 75 percentile in Science\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, \n                                  face = \"bold\", hjust = 1)) + \n  theme(axis.text = element_text(size = 7))\n  \np2 &lt;- ggplot(SBottom25, \n       aes(x= SchoolID, y = StudentCount)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"10 Schools with the most number of students scoring below 25 percentile in Science\") + \n  theme_economist() +\n  theme(plot.title = element_text(size = 10, \n                                  face = \"bold\", hjust = 1)) +\n  theme(axis.text = element_text(size = 7))\n\n(p1 / p2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe number of students who did well differs among schools.\nSchool 70200001 has the most number of students scoring in the top 75 percentile range in Maths and Science. Similarly, School 70200115 has the most number of students scoring in the bottom 25 percentile range in both Maths and Science."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "",
    "text": "According to a report by the Ministry of Sustainability and Environment, the infographic below indicates that\n\nFrom 1948 to 2016, the annual mean temperatures rose at an average rate of 0.25 °C per decade. The daily mean temperatures are projected to increase by 1.4 °C to 4.6 °C.\nFrom 1980 to 2016, annual total rainfall rose at an average rate of 101 mm per decade. The contrast between the wet months (November to January) and dry months (February and June to September) is likely to be more pronounced.\n\n\nThe following figure is taken from Meteorological Service Singapore (MSS) website. It shows the mean monthly temperature variation (ºC) from 1991 to 2020 at Changi Climate Station.\n\nCompared to countries in the temperate regions, temperatures in Singapore vary little from month to month. The daily temperature range has a minimum usually not falling below 23-25ºC during the night and a maximum not rising above 31-33ºC during the day. May has the highest average monthly temperature (24-hour mean of 28.6ºC) and December and January are the coolest (24-hour mean of 26.8ºC).\nAs a visual analytics greenhorn, we will apply newly acquired visual interactivity and visualising uncertainty methods to validate the claims presented above.\n\n\nIn this exercise, we are required to:\n\nSelect a weather station and download historical daily temperature or rainfall data from Meteorological Service Singapore (MSS) website,\nSelect either daily temperature or rainfall records of a month of the year 1983, 1993, 2003, 2013 and 2023 and create an analytics-driven data visualisation,\nApply appropriate interactive techniques to enhance the user experience in data discovery and/or visual story-telling."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "",
    "text": "In this exercise, we are required to:\n\nSelect a weather station and download historical daily temperature or rainfall data from Meteorological Service Singapore (MSS) website,\nSelect either daily temperature or rainfall records of a month of the year 1983, 1993, 2003, 2013 and 2023 and create an analytics-driven data visualisation,\nApply appropriate interactive techniques to enhance the user experience in data discovery and/or visual story-telling."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-r-packages",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "2.1 Installing R packages",
    "text": "2.1 Installing R packages\nThe code below uses p_load() of the Pacman package to check if all the required packages are installed on the laptop. If they are, then they will be launched into the R environment.\n\npacman::p_load(tidyverse, ggstatsplot, plotly, ggplot2, ggdist)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-data",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\nBased on the MSS website, we can download the monthly data of a selected climate station each time. As such, I have written a robotic process automation bot using UIPath software to download all the monthly data recorded at Changi climate station, the oldest climate station near Changi Airport, and then combine all the CSV files and save the data in one CSV file.\n\nweather &lt;- read_csv(\"data/Changi.csv\")\nglimpse(weather)\n\nRows: 16,071\nColumns: 13\n$ Station                     &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"C…\n$ Year                        &lt;dbl&gt; 1980, 1980, 1980, 1980, 1980, 1980, 1980, …\n$ Month                       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Day                         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…\n$ `Daily Rainfall Total (mm)` &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 8.0, 9.1, 7.9, 0.0, 0.…\n$ `Daily Rainfall Total`      &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Highest 30 Min Rainfall`   &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Highest 120 Min Rainfall`  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Mean Temperature`          &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Maximum Temperature`       &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Minimum Temperature`       &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Mean Wind Speed (km/h)`    &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…\n$ `Max Wind Speed (km/h)`     &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#change-data-type",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#change-data-type",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "2.3 Change data type",
    "text": "2.3 Change data type\nThis exercise will focus on the analysis of how temperature changes over the years so we select the relevant columns and the temperature column names are shortened for easy reference.\nWe can see that columns “Year”, “Month” and “Day” are double data types whereas “Mean Temperature”, “Maximum Temperature”, and “Minimum Temperature” are character data types. These are wrongly classified.\nLet’s change “Year” and “Day” to integer data type, and the temperature-related variables should be numeric.\nAs for the values in the column “Month”, they will be replaced by the abbreviation of the respective months.\nWe remove the data records for years 1980 and 1981 as there are no temperature records.\n\nweather &lt;- weather %&gt;% \n          select(2:4, 9:11, \"MeanTemp\" = 9, \"MaxTemp\" = 10, \"MinTemp\" = 11 )\n\nweather$Year &lt;- as.integer(weather$Year)\nweather$Month &lt;- month.abb[weather$Month]\nweather$Day &lt;- as.integer(weather$Day)\nweather$MeanTemp &lt;- as.numeric(weather$MeanTemp)\nweather$MaxTemp &lt;- as.numeric(weather$MaxTemp)\nweather$MinTemp &lt;- as.numeric(weather$MinTemp)\n\nweather &lt;- weather %&gt;% \n          filter(Year != 1980 & Year != 1981)\nglimpse(weather)\n\nRows: 15,340\nColumns: 6\n$ Year     &lt;int&gt; 1982, 1982, 1982, 1982, 1982, 1982, 1982, 1982, 1982, 1982, 1…\n$ Month    &lt;chr&gt; \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\", \"Jan\"…\n$ Day      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ MeanTemp &lt;dbl&gt; 25.3, 24.7, 25.7, 26.3, 25.8, 23.7, 23.7, 24.4, 25.4, 25.6, 2…\n$ MaxTemp  &lt;dbl&gt; 29.4, 26.2, 27.2, 29.8, 28.8, 24.9, 25.2, 27.6, 28.3, 29.3, 2…\n$ MinTemp  &lt;dbl&gt; 23.0, 23.5, 24.0, 24.1, 23.5, 21.9, 22.4, 22.8, 23.5, 23.2, 2…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#filter-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#filter-data",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "2.4 Filter data",
    "text": "2.4 Filter data\nFor this exercise, we will focus on the daily temperature records in the years 1983, 1993, 2003, 2013 and 2023. Hence, we will filter the data rows by the years.\n\nweather_data &lt;- weather %&gt;% \n          filter(Year %in% c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"))\ncolSums(is.na(weather_data))\n\n    Year    Month      Day MeanTemp  MaxTemp  MinTemp \n       0        0        0        0        0        0 \n\nsummary(weather_data)\n\n      Year         Month                Day           MeanTemp    \n Min.   :1983   Length:1825        Min.   : 1.00   Min.   :23.00  \n 1st Qu.:1993   Class :character   1st Qu.: 8.00   1st Qu.:26.90  \n Median :2003   Mode  :character   Median :16.00   Median :27.70  \n Mean   :2003                      Mean   :15.72   Mean   :27.73  \n 3rd Qu.:2013                      3rd Qu.:23.00   3rd Qu.:28.70  \n Max.   :2023                      Max.   :31.00   Max.   :30.70  \n    MaxTemp         MinTemp     \n Min.   :23.80   Min.   :20.90  \n 1st Qu.:30.70   1st Qu.:24.10  \n Median :31.80   Median :25.00  \n Mean   :31.53   Mean   :25.04  \n 3rd Qu.:32.60   3rd Qu.:26.00  \n Max.   :35.80   Max.   :29.00  \n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThere are a total of 1825 observations with 6 variables.\nThere are no missing data in these 6 variables.\nThe average daily mean, maximum and minimum temperatures for these selected years are 27.73°C, 31.53°C and 25.04°C respectively."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#create-useful-columns-and-summarise-dataset",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#create-useful-columns-and-summarise-dataset",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "2.5 Create useful columns and summarise dataset",
    "text": "2.5 Create useful columns and summarise dataset\nIt might be useful to look at the trend of daily temperatures by month of each year. Hence we will group the data by year and month, and then averaging the mean temperature and getting the maximum and minimum temperature in each month.\nTo plot a line chart, it might be good to have a column to show the dates, hence we create two columns to show the dates and day of the year.\nLastly, we also want to visualise the 99% confidence interval from the annual mean temperatures, hence we created another dataset to summarize the mean and standard deviation.\n\nweather_data$DDate &lt;- as.Date(paste(weather_data$Year, \n                                    weather_data$Month, \n                                    weather_data$Day, sep = \"-\"), \n                              format = \"%Y-%b-%d\")\n\n# join 1993 Jan 1 to 1983 Dec 31 by setting it to Day 365+1 = 366. \n#Do the same for the other years\nweather_data &lt;- weather_data %&gt;% \n  mutate(DayOfYear = yday(DDate) + (Year - 1983)/10 * 365)\n\nweather_month &lt;- weather_data %&gt;% \n                group_by(Year, Month) %&gt;% \n                summarise(AveMeanTemp = mean(MeanTemp),\n                          MaxMaxTemp = max(MaxTemp),\n                          MinMinTemp = min(MinTemp))\n\nAve_temp &lt;- weather_month %&gt;% \n  mutate(MonthOfYear = match(Month, month.abb) + (Year - 1983)/10 * 12 ) \n\nmean_error &lt;- weather_data %&gt;%\n  group_by(Year) %&gt;%\n  summarise(n = n(), Temp = mean(MeanTemp), sd = sd(MeanTemp)) %&gt;%\n  mutate(se = sd/sqrt(n-1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overall-distribution-of-temperature-across-the-5-years",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overall-distribution-of-temperature-across-the-5-years",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "3.1 Overall distribution of temperature across the 5 years",
    "text": "3.1 Overall distribution of temperature across the 5 years\nLet’s take a look at the distribution of days with temperature values binned in 0.2ºC for the selected years.\n\n\nShow the code\nggplot(data = weather_data, aes(x = MeanTemp)) +\n  geom_histogram(bins = 50, \n                 binwidth = 0.2,\n                 boundary = 100,\n                 color=\"grey\", \n                 fill=\"lightblue\") +\n  geom_density(aes(y = after_stat(density) * nrow(weather_data) * 0.2),\n                   colour = \"darkgreen\") +\n  geom_vline(data = weather_data, \n             aes(xintercept = mean(MeanTemp)),\n             linetype = \"dashed\", linewidth = 1, colour = \"brown\") +\n  geom_label(aes(x = 28.5, y = 120, \n                 label = paste0(\"Mean : \", round(mean(MeanTemp),2), \"°C\")),\n            stat = \"unique\", colour = \"brown\", fill = \"transparent\") +\n  theme_minimal() +\n  labs(title = \"Distribution of Daily Mean Temperatures\", \n       subtitle = \"For years 1983, 1993, 2003, 2013 and 2023\",\n       y = \"Number of days\",\n       x = \"Daily mean temperatures (°C)\",\n       caption = \"Data from Meteorological Service Singapore website\") +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nIt looks like a normal distribution with an average daily mean temperature of 27.73 ºC.\nHowever, it is in fact a little left-skewed (there are everal days with temperatures below 25 ºC).\n\n\n\n\n\nShow the code\ngg &lt;- ggplot(weather_data, aes(x = DayOfYear, y = MeanTemp, \n                         color = factor(Year))) +\n    geom_line(linewidth = 0.1) +\n    geom_point(aes(text = paste(\"Date:\", DDate,\n                                \"&lt;br&gt;MeanTemp:\", MeanTemp, \"ºC\"))) +\n    scale_x_continuous(breaks = c(0, 365, 365 *2, 365 *3, 365 * 4), \n                       labels = c(1983, 1993, 2003, 2013, 2023)) +\n    labs(x = \"Year\", y = \"Daily mean temperature (ºC)\", color = \"Year\",\n         title = \"Trend of Daily Mean Temperature in Years 1983, 1993, 2003, 2013 and 2023\", \n         subtitle = \"Gentle trend line sloping upwards from 1993\",\n         caption = \"Data from Meteorological Service Singapore website\") +\n    geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, 3), \n                se = FALSE, color = \"black\") +\n    theme_minimal()\n\nggplotly(gg, tooltip = \"text\") %&gt;%\n    layout(title = list(text = \n                        paste0(gg$labels$title, \"&lt;br&gt;\", \"&lt;sup&gt;\", \n                               gg$labels$subtitle, \"&lt;/sup&gt;\"),\n                        font = list(weight = \"bold\")),\n    annotations = list(text = gg$labels$caption,\n                      xref = \"paper\", yref = \"paper\",\n                      x = 1000, y = 24,\n                      xanchor = \"right\", yanchor = \"top\",\n                      showarrow = FALSE)) \n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe pattern is similar for the years 1993, 2003, 2013, and 2023 as we have cooler days in January and December and hotter days in May and June.\nHowever, in 1983, the hottest days are in April and the days in January are not as cool as the other days in January of other years.\nFrom the trend line (in black), we can see that the daily mean temperature is gently increasing from 1993 onwards."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#distribution-of-daily-mean-temperatures-by-months",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#distribution-of-daily-mean-temperatures-by-months",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "3.2 Distribution of daily mean temperatures by months",
    "text": "3.2 Distribution of daily mean temperatures by months\n\n\nShow the code\ngg &lt;- ggplot(weather_data, \n       aes(x = factor(Month, levels = month.abb), y = MeanTemp)) +\n  geom_violin(color = \"navy\", fill = \"lightblue\") +\n  geom_hline(data = weather_data, \n             aes(yintercept = mean(MeanTemp)),\n             linetype = \"dashed\", size = 1, colour = \"brown\") +\n  geom_text(aes(x = 4.5, y = 27.3, \n                 label = paste0(\"Mean : \", round(mean(MeanTemp),2), \"°C\")), \n            colour = \"brown\") +\n  stat_summary(fun = mean, geom = \"point\", \n               shape = 20, size = 3, color = \"orange\",\n               aes(text = paste0(\"Mean : \", round(after_stat(y), 2), \"°C\"))) +\n  theme_minimal() +\n  labs(title = \"Daily mean temperature across each month of years \\n1983, 1993, 2003, 2013 and 2023\",\n       subtitle = \"November to February are cooler as compared to the rest of the year\",\n        y = \"Daily mean Temperatures (°C)\",\n        x = \"Month\",\n        caption = \"Data from Meteorological Service Singapore website\")\n\nggplotly(gg, tooltip = \"text\") %&gt;%\n    layout(title = list(text =\n                        paste0(gg$labels$title, \"&lt;br&gt;\", \"&lt;sup&gt;\",\n                               gg$labels$subtitle, \"&lt;/sup&gt;\"),\n                        font = list(weight = \"bold\")))\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe box plot above resonates well with what was mentioned on the MSS website.\n\n‘The daily temperature range has a minimum usually not falling below 23-25ºC during the night and a maximum not rising above 31-33ºC during the day.’ Indeed from the plot above, the temperature ranges from 23ºC to 31ºC.\n‘May has the highest average monthly temperature (24-hour mean of 28.6ºC) and December and January are the coolest (24-hour mean of 26.8ºC).’ From the plot above, May and June have the highest average monthly temperatures close to 29ºC, whereas December and January are the coolest with average temperatures below 27ºC."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#trends-of-daily-mean-temperature-by-year",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#trends-of-daily-mean-temperature-by-year",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "3.3 Trends of daily mean temperature by year",
    "text": "3.3 Trends of daily mean temperature by year\n\n\nShow the code\ngg &lt;- ggplot(weather_month, \n       aes(x = factor(Month, levels = month.abb), y = AveMeanTemp, \n           group = Year, color = factor(Year))) +\n    geom_point(aes(color = factor(Year),\n                   text = paste(Year, \"-\", Month,\n                                \"&lt;br&gt;MeanTemp:\", round(AveMeanTemp, 2), \"ºC\"))) +\n    geom_line() +\n    labs(x = \"Month\", \n       y = \"Mean Temperatures (°C)\", \n       title = \"Mean Temperatures variation throughout the year\",\n       subtitle = \"Hotter days from mid May 2023 as compared to years 1983, 1993, 2003 and 2013\",\n       caption = \"Data from Meteorological Service Singapore website\") +\n  scale_color_discrete(name = \"Year\") +\n  theme_minimal() + \n  theme(plot.title = element_text(face = \"bold\"))\n\nggplotly(gg, tooltip = \"text\") %&gt;%\n    layout(title = list(text = \n                        paste0(gg$labels$title, \"&lt;br&gt;\", \"&lt;sup&gt;\", \n                               gg$labels$subtitle, \"&lt;/sup&gt;\"),\n                        font = list(weight = \"bold\")))\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe mean temperatures in 2023 are higher from May to December as compared to the other 4 years.\n\n\nUsing the calendar heatmap, we are able to see that more months in 2023 are hotter as compared to the previous years.\n\n\nShow the code\ngg &lt;- ggplot(weather_month, aes(factor(Month, levels = month.abb), factor(Year), \n                          fill = AveMeanTemp)) + \n    geom_tile(color = \"white\",\n              aes(text = paste0(Year, \"-\", Month,\n                                \"&lt;br&gt;Temp:\", round(AveMeanTemp, 2), \"°C\"))) + \n    theme_minimal() + \n    scale_fill_gradient(name = \"Temperature\",\n                        low = \"sky blue\", \n                        high = \"dark blue\") +\n    labs(x = NULL, y = NULL, \n         title = \"Mean temperatures by year and month\",\n         subtitle = \"Hotter in more months of 2023 as compared to the other years\")\n\nggplotly(gg, tooltip = \"text\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#confidence-interval-of-annual-mean-temperatures-by-year",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#confidence-interval-of-annual-mean-temperatures-by-year",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "3.4 Confidence interval of annual mean temperatures by year",
    "text": "3.4 Confidence interval of annual mean temperatures by year\n\n\nShow the code\nmodel &lt;- lm(Temp ~ Year, mean_error)\ny_intercept = coef(model)[1] \nslope_coeff = coef(model)[2]\nadjust_yintercept = slope_coeff * 1973 + y_intercept\n\ngg &lt;- ggplot(mean_error) +\n       geom_errorbar(aes(x = factor(Year), ymin = Temp - 2.58 * se, \n                      ymax = Temp+2.58*se), \n                      width=0.2, colour=\"black\", \n                      alpha=0.9, size=0.5) +\n       geom_point(aes(x = factor(Year), y = Temp, \n             text = paste0(\"Year:\", `Year`, \n                          \"&lt;br&gt;Avg. Temp:\", round(Temp, digits = 2),\n                          \"&lt;br&gt;95% CI:[\", \n                          round((Temp - 2.58 * se), digits = 2), \",\",\n                          round((Temp + 2.58 * se), digits = 2),\"]\")),\n             stat=\"identity\", color=\"darkred\", \n             size = 1.5, alpha = 1) +\n       geom_abline(slope = round(slope_coeff,4) * 10, \n                   intercept = adjust_yintercept,\n                   untf = TRUE,\n                   color = \"blue\",\n                   linetype = \"dashed\")+\n       geom_text(aes(x = 4, y = 28, colour = \"blue\",\n                     label = paste0(\"Temp=\", \n                                    round(slope_coeff, 4), \"* Year + \",\n                                    round(y_intercept, 4)))) +\n       labs (x = \"Year\", y = \"Annual mean temperatures (°C)\",\n             title = \"99% Confidence interval of annual mean temperatures by year\",\n             subtitle = \"Confidence interval for 2023 does not overlap with the rest\",\n             caption = \"Data from Meteorological Service Singapore website\") +\n       theme_minimal() + \n       theme(axis.text.x = element_text(vjust = 0.5, hjust=1),\n             plot.title = element_text(face = \"bold\", size = 12))\n\nggplotly(gg, tooltip = \"text\") %&gt;%\n    layout(title = list(text = \n                        paste0(gg$labels$title, \"&lt;br&gt;\", \"&lt;sup&gt;\", \n                               gg$labels$subtitle, \"&lt;/sup&gt;\"),\n                        font = list(weight = \"bold\")),\n           showlegend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe 99% confidence interval of the average daily mean temperature of 2023 is the only one that does not overlap with the other years’ confidence interval. That means that its confidence interval is too far off from the rest.\nA linear regression is calculated for all the 5 points and the slope of the regression line is 0.0125°C. This means that for every 10 years, the annual mean temperature increases by 0.125°C (somewhat far from what is stated on the MSS website).\n\n\n\nSince we have the temperature data from 1982 to 2023, let fit them into the linear regression model.\n\n\nShow the code\nmean_error_all &lt;- weather %&gt;%\n  group_by(Year) %&gt;%\n  summarise(n = n(), Temp = mean(MeanTemp), sd = sd(MeanTemp)) %&gt;%\n  mutate(se = sd/sqrt(n-1))\n\nmodel &lt;- lm(Temp ~ Year, mean_error_all)\ny_intercept = coef(model)[1] \nslope_coeff = coef(model)[2]\nadjust_yintercept = slope_coeff * 1982 + y_intercept\n\ngg &lt;- ggplot(mean_error_all) +\n       geom_errorbar(aes(x = factor(Year), ymin = Temp - 2.58 * se, \n                      ymax = Temp+2.58*se), \n                      width=0.2, colour=\"black\", \n                      alpha=0.9, size=0.5) +\n       geom_point(aes(x = factor(Year), y = Temp, \n             text = paste0(\"Year:\", `Year`, \n                          \"&lt;br&gt;Avg. Temp:\", round(Temp, digits = 2),\n                          \"&lt;br&gt;95% CI:[\", \n                          round((Temp - 2.58 * se), digits = 2), \",\",\n                          round((Temp + 2.58 * se), digits = 2),\"]\")),\n             stat=\"identity\", color=\"darkred\", \n             size = 1.5, alpha = 1) +\n       geom_abline(slope = round(slope_coeff, 4), \n                   intercept = adjust_yintercept,\n                   untf = TRUE,\n                   color = \"blue\",\n                   linetype = \"dashed\")+\n       geom_text(aes(x = 11, y = 27.8, colour = \"blue\",\n                     label = paste0(\"Temp=\", \n                                    round(slope_coeff, 4), \"* Year \",\n                                    round(y_intercept, 4)))) +\n       labs (x = \"Year\", y = \"Annual mean temperatures (°C)\",\n             title = \"99% Confidence interval of annual mean temperatures by year\",\n             subtitle = \"From 1982 to 2023\",\n             caption = \"Data from Meteorological Service Singapore website\") +\n       theme_minimal() + \n       theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),\n             plot.title = element_text(face = \"bold\", size = 12))\n\nggplotly(gg, tooltip = \"text\") %&gt;%\n    layout(title = list(text = \n                        paste0(gg$labels$title, \"&lt;br&gt;\", \"&lt;sup&gt;\", \n                               gg$labels$subtitle, \"&lt;/sup&gt;\"),\n                        font = list(weight = \"bold\")),\n           showlegend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nThe slope of the regression line is 0.0217, which means for every year, there is an increase of 0.0217°C. Hence, for every decade, there will be an increase of approximately 0.22°C, which is quite similar to what was stated in the infographic by MSE.\nAccording to Figure 1 on this website, the annual average temperatures from 1948 to 1981 are generally lower than 27°C, which makes the difference in temperatures as compared to the later decades wider. This means an increase of approximately 0.25°C per decade from 1948 to 2023 is possible."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#one-sample-test-on-daily-mean-temperature",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#one-sample-test-on-daily-mean-temperature",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "4.1 One-sample test on Daily Mean Temperature",
    "text": "4.1 One-sample test on Daily Mean Temperature\nIn this MSS annual report 2023, the annual mean temperature in 2023 was 28.2°C. Let us conduct a one-sample test to compare with the 5 years’ records.\n\n\nShow the code\ngghistostats(data = weather_data, x = MeanTemp,\n            type = \"bayes\",\n            test.value = 28.2) +\n  labs(x = \"Daily mean temperatures\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of results\n\n\n\nlog(BF01) = - 115.31 is a very small negative value, which means that the past 5 years’ mean temperatures are significantly different from the test value (i.e. 28.2°C)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#one-way-anova-test-on-daily-mean-temperatures-by-year",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#one-way-anova-test-on-daily-mean-temperatures-by-year",
    "title": "Take-home Exercise 3: Be Weatherwise Or Otherwise",
    "section": "4.2 One-way Anova test on daily mean temperatures by year",
    "text": "4.2 One-way Anova test on daily mean temperatures by year\n\n\nShow the code\nggbetweenstats(data = weather_data, x = Year, y = MeanTemp,\n              type = \"p\",\n              mean.ci = TRUE, \n              pairwise.comparisons = TRUE, \n              pairwise.display = \"s\", #show significant pair only\n              p.adjust.method = \"fdr\",\n              messages = FALSE) +\n  labs(y = \"Daily mean temperatures\",\n       title = \"One-way Anova Test on Daily Mean Temperatures by Year\")\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of results\n\n\n\nFrom the above Anova test, we can conclude that the annual mean temperatures are significantly different in 2023 when compared with the years 1983, 1993, 2003, and 2013. The annual mean temperatures are significantly different for the years 1993 and 2003 too."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#loading-r-packages",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "2.1 Loading R Packages",
    "text": "2.1 Loading R Packages\nWe will use the following R packages in this exercise:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that creates interactive tables on html pages.\ntidyverse, a family of modern R packages specially designed to support data science, analysis, and communication tasks including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#importing-data",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe will use the exam_data which consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in the CSV file format, hence we use read_csv() function of the readr package (one of the tidyverse packages).\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#tooltip-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#tooltip-effect",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.1 Tooltip effect",
    "text": "3.1 Tooltip effect\nBelow is a typical code chunk to plot an interactive statistical graph by using ggiraph package.\nThe code chunk consists of two parts. First, a ggplot object will be created with an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()). Then, girafe() of ggiraph is used to create an interactive svg object to be displayed on a html page.\n\nTooltip(single info)Tooltip(multiple info)Tooltip (Statistics)Tooltip(Customization)\n\n\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(tooltip = ID),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\n\n\n\nWe can add multiple information in the tooltip.\n\n\nShow the code\nexam_data &lt;- exam_data %&gt;%\n  mutate(AVESCORE = round(rowMeans(\n    exam_data[, c(\"ENGLISH\", \"MATHS\", \"SCIENCE\")]), digits = 2))\n\nexam_tooltip &lt;- c(paste0(\"Name = \", exam_data$ID, \n                         \"\\nGender = \", exam_data$GENDER,\n                         \"\\nClass = \", exam_data$CLASS,\n                          \"\\nAve Score = \", exam_data$AVESCORE,\n                          \"\\n Eng,Math,Sci: \",exam_data$ENGLISH, \",\",\n                           exam_data$MATHS, \",\", exam_data$SCIENCE))\n  \np &lt;- ggplot(data=exam_data,\n          aes(x = AVESCORE)) +\n    geom_dotplot_interactive(aes(tooltip = exam_tooltip),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\n\n\n\nWe can add stat_summary() calculations in ggplot.\n\n#create a function to generate the tooltip\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\") +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, linewidth = 0.2) +\n  theme_classic()\n\ngirafe(ggobj = gg_point,\n       width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\n\n\nWe can customise the tooltip styles using options in girafe.\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(tooltip = ID),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618,\n       options = list(\n         opts_tooltip(css = \"background-color: yellow\")))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#hover-effect-with-id",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#hover-effect-with-id",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.2 Hover effect with ID",
    "text": "3.2 Hover effect with ID\nWe can also use data_id specified in aes() to produce the hovering effect.\n\ndata_iddata_id (+ tooltip)data_id(with styles)data_id(customised with tooltip!)\n\n\nThe following code chunk will select all the students who belong to the same class as data_id = CLASS.\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(data_id = CLASS),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\n\n\n\nWe can combine data_id and tooltip in the interactivity.\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(data_id = CLASS,\n                                 tooltip = ID),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,\n       width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\n\n\n\nWe can use opts_hover() and opts_hover_inv() to customise the hovering styles.\n\nopts_hover(): effects on hovered geometrics\nopts_hover_inv(): effects on other not-selected geometrics when one geometric is hovered.\n\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(data_id = CLASS),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,                             \n  width_svg = 6, height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\")))   \n\n\n\n\n\n\n\n\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS)) +\n    geom_dotplot_interactive(aes(tooltip = paste0(\"Class = \", CLASS),\n                                 data_id = CLASS),\n                             stackgroups = TRUE,\n                             binwidth = 1,\n                             method = \"histodot\") +\n    scale_y_continuous(NULL, breaks = NULL) +\n    theme_classic()\n\ngirafe(ggobj = p,                             \n  width_svg = 6, height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\")))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#onclick-interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#onclick-interactivity",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.3 OnClick Interactivity",
    "text": "3.3 OnClick Interactivity\nonclick argument of ggiraph provides hotlink interactivity on the web.\n\n\nShow the code\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n                      aes(tooltip = \"Click me\",\n                        onclick = onclick),              \n                      stackgroups = TRUE,                  \n                      binwidth = 1,                        \n                      method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL) +\n  theme_classic()\n\ngirafe(ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.4 Coordinated Multiple Views with ggiraph",
    "text": "3.4 Coordinated Multiple Views with ggiraph\nCoordinated multiple views refer to the visualisation when a data point of one of the plots is selected, the corresponding data point ID on the other plots will be highlighted too.\n\n\nShow the code\np1 &lt;- ggplot(data = exam_data,aes(x = MATHS)) +\n      geom_dotplot_interactive(aes(tooltip= ID, data_id = ID),\n                              stackgroups = TRUE,\n                              binwidth = 1,\n                              method = \"histodot\") +\n      coord_cartesian(xlim = c(0,100)) +\n      scale_y_continuous(NULL, breaks = NULL) +\n      theme_classic()\n      \np2 &lt;- ggplot(data = exam_data, aes(x = ENGLISH)) +\n      geom_dotplot_interactive(aes(tooltip = ID, data_id = ID),\n                              stackgroups = TRUE,\n                              binwidth = 1,\n                              method = \"histodot\") +\n      coord_cartesian(xlim = c(0,100)) +\n      scale_y_continuous(NULL, breaks = NULL)+\n      theme_classic()\n\ngirafe(code = print(p1 / p2),\n    width_svg = 6,\n    height_svg = 3.8,\n    options = list(\n    opts_hover(css = \"fill: #202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation-plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation-plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.5 Interactive Data Visualisation: plotly methods",
    "text": "3.5 Interactive Data Visualisation: plotly methods\nPlotly’s R graphing library creates interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics.\nThere are two ways to create interactive graphs by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.5.1 plot_ly()\nThe syntax for ploty_ly() is different from ggplot().\n\nBasicVisual variables\n\n\n\n\nShow the code\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\n\nShow the code\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH,\n             color = ~RACE) \n\n\n\n\n\n\n\n\n\n\n\n\nInteractivity of plot_ly()\n\n\n\n\nFilter: When you click on the legend “Chinese”, the data points for “Chinese” are filtered away.\nTooltip: The tooltip is automatically generated and the colour of the the tooltip is synchronous with the legend colour.\nZoom-in ability: Select a range of data points, and the plot will zoom in on these data points.\nAvailable tools to use: Lasso selection, compare data on hover etc.\n\n\n\n\n\n\n\n\n3.5.2 ggplotly()\nUse ggplot() and then wrap ggplotly over. The advantage of this is no need more follow the syntax used in plotly().\n\nBasicMultiple Views\n\n\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n          aes(x = MATHS, y = ENGLISH)) +\n    geom_point(size = 1) +\n    coord_cartesian(xlim = c(0,100),\n                    ylim = c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\nShow the code\n# specify the data table to highlight in coordinate multiple views\nd &lt;- highlight_key(exam_data)\n\np1 &lt;- ggplot(data = d, \n            aes(x = MATHS, y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  theme_classic()\n\np2 &lt;- ggplot(data = d, \n            aes(x = MATHS, y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  theme_classic()\n\n# combine 2 ggplotly plots together\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-table-dt-package",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-table-dt-package",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "4.1 Interactive Data Table: DT package",
    "text": "4.1 Interactive Data Table: DT package\nDT package is a wrapper of the JavaScript Library DataTables.\nData objects in R can be rendered as HTML tables using the JavaScript library DataTables.\n\n\nShow the code\nDT::datatable(exam_data, \n              exam_data[c(\"ID\",\"CLASS\",\"GENDER\",\"RACE\",\n                          \"ENGLISH\",\"MATHS\",\"SCIENCE\")],\n              class= \"compact\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#linked-brushing-crosstalk-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#linked-brushing-crosstalk-method",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "4.2 Linked brushing: crosstalk method",
    "text": "4.2 Linked brushing: crosstalk method\n\n\nShow the code\nd &lt;- highlight_key(exam_data[c(\"ID\",\"CLASS\",\"GENDER\",\n                               \"RACE\",\"ENGLISH\",\"MATHS\",\"SCIENCE\")]) \np &lt;- ggplot(data = d, \n            aes(x= MATHS, y = ENGLISH)) + \n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\n# subset of the selected data points\ngg &lt;- highlight(ggplotly(p), \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "",
    "text": "The code below uses p_load() of the pacman package to check if tidyverse packages are installed in the laptop. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\nLet’s use read_csv function of readr package to load the data from Exam_data.csv into R.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "",
    "text": "The code below uses p_load() of the pacman package to check if tidyverse packages are installed in the laptop. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "",
    "text": "Let’s use read_csv function of readr package to load the data from Exam_data.csv into R.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#examination-scores-distribution",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#examination-scores-distribution",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "2.1 Examination scores distribution",
    "text": "2.1 Examination scores distribution\nLet’s create boxplots for the performance of 3 subjects and arrange them in a row for easy comparison.\n\nlibrary(\"ggpubr\")\nboxplt1 &lt;- ggplot(data = exam_data,   \n  aes(y = MATHS)) +   \n  geom_boxplot() \nboxplt2 &lt;- ggplot(data = exam_data,   \n  aes(y = ENGLISH)) +   \n  geom_boxplot()\nboxplt3 &lt;- ggplot(data = exam_data,   \n  aes(y = SCIENCE)) +   \n  geom_boxplot()\nggarrange(boxplt1, boxplt2, boxplt3, ncol = 3, nrow = 1)\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nStudents did better in Maths as compared to English and Science. There are some outliers in Maths and English boxplots where students did very poorly.\n\n\nLet’s dive a little deeper to see how each class performs.\n\nggplot(data = exam_data,   \n  aes(x = CLASS, y = MATHS)) +   \n  geom_boxplot()+\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour = \"red\",        \n               size = 3) \n\n\n\nggplot(data = exam_data,   \n  aes(x = CLASS, y = ENGLISH)) +   \n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour = \"red\",        \n               size = 3) \n\n\n\nggplot(data = exam_data,   \n  aes(x = CLASS, y = SCIENCE)) +   \n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour = \"red\",        \n               size = 3) \n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThere are 9 classes in this dataset.\nStudents from Class 3I have poorer performance in all 3 subjects (many failed 3 subjects), whereas students from Class 3A have better performance in all 3 subjects."
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#race-distribution",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#race-distribution",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "2.2 Race distribution",
    "text": "2.2 Race distribution\nLet’s take a look at the students’ race distribution:\n\nggplot(data = exam_data, \n       aes(x = fct_infreq(RACE))) +\n  geom_bar() +\n  labs(title=\"Distribution of race\",\n       x = \"Race\",\n       y = \"Number of students\") + \n  ylim(0, 210) +\n  geom_text(aes(label = after_stat(count)), \n            stat = \"count\", vjust = -0.5, colour = \"brown\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFrom the bar chart above, the majority of the students are Chinese, followed by Malay.\n\n\nWhat about the race distribution in each class?\n\nggplot(data = exam_data) +\n  geom_bar(mapping = aes(x =CLASS, fill = RACE))\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nClass 3A has more Chinese students whereas Class 3I has more Malay students.\nClass 3I has the fewest number of students."
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#gender-distribution",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#gender-distribution",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "2.3 Gender distribution",
    "text": "2.3 Gender distribution\nLet’s take a look at the students’ gender distribution:\n\nggplot(data = exam_data, \n       aes(x = fct_infreq(GENDER))) +\n  geom_bar() +\n  labs(title=\"Distribution of gender\",\n       x = \"Gender\",\n       y = \"Number of students\") + \n  ylim(0, 210) +\n  geom_text(aes(label = after_stat(count)), \n            stat = \"count\", vjust = -0.5, colour = \"brown\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere are more female students than male students.\n\n\nWhat about the distribution of gender in each class?\n\nggplot(data = exam_data) +\n  geom_bar(mapping = aes(x =CLASS, fill = GENDER))\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere are more female students in Class 3B and fewer female students in Class 3I."
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#correlation-between-performances-of-different-subjects",
    "href": "Hands-on_Ex/Hands-On_Ex01/Hands-on_Ex01.html#correlation-between-performances-of-different-subjects",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics",
    "section": "2.4 Correlation between performances of different subjects",
    "text": "2.4 Correlation between performances of different subjects\nLet’s see if there is any correlation between the performance of Maths vs English, Maths vs Science, and English vs Science via scatter plots.\n\nggplot(data=exam_data,\n  aes(x = MATHS,y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(linewidth = 0.5) +\n  # use the same axis range\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n\n\nggplot(data=exam_data,\n  aes(x = MATHS,y = SCIENCE)) +\n  geom_point() + \n  geom_smooth(linewidth = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n\n\nggplot(data=exam_data,\n  aes(x = ENGLISH, y = SCIENCE)) +\n  geom_point() + \n  geom_smooth(linewidth = 0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\nAll 3 scatter plots show some positive correlation between the performances of the subjects. However, we would need to calculate the correlation coefficients to determine how strong the correlations are."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "In this exercise, we are using ggplot2 extensions to create more elegant and effective statistical graphics using ggrepel, ggthemes, hrbrthemes, and patchwork packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-launching-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-launching-the-required-libraries",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "2.1 Installing and launching the required libraries",
    "text": "2.1 Installing and launching the required libraries\nThe code below uses p_load() of the Pacman package to check if all the following packages are installed on the laptop. If they are, then they will be launched into R.\n\ntidyverse\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figures created using ggplot2.\n\n\npacman::p_load(tidyverse, ggrepel,\n               ggthemes, hrbrthemes,\n               patchwork)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "2.2 Importing the data",
    "text": "2.2 Importing the data\nExam_data consists of year-end examination grades of a cohort of primary 3 students from a local school. It is in the CSV file format.\nThe code chunk below imports exam_data.csv into the R environment by using read_csv() function of the readr package (one of the tidyverse packages).\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThis data is about students’ examination scores for their 3 subjects (English, Maths, and Science) from various classes in Primary 3 from a school.\nThere are 4 categorical variables: ID, CLASS, GENDER, and RACE, and 3 continuous variables: ENGLISH, MATHS, and SCIENCE.\nOut of the 3 subjects, Maths has the higher mean and median score."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "3.1 Working with ggrepel",
    "text": "3.1 Working with ggrepel\nLet’s replace geom_label() by geom_label_repel().\n\nggplot(data = exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, size = 0.5) +\n  geom_label_repel(aes(label = ID), \n              fontface = \"bold\") +\n  coord_cartesian(xlim = c(0, 100), \n                  ylim = c(0, 100)) +\n  ggtitle(\"English scores versus Maths score for Primary 3 students\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThough the plot is neater, the annotation appears only at some data points as many points are overlapped. There is an option to increase max.overlaps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "4.1 Working with ggtheme package",
    "text": "4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nCheck out some of the available themes here:\n\nEconomistExcelFewSolarized\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100,\n                  color = \"grey25\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores (Economist theme)\") +\n  theme_economist()\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100,\n                  color = \"grey25\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores (Excel theme)\") +\n  theme_excel()\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100,\n                  color = \"grey25\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores (Few theme)\") +\n  theme_few()\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100,\n                  color = \"grey25\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Maths scores (Solarized theme)\") +\n  theme_solarized()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbrthemes-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbrthemes-package",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "4.2 Working with hrbrthemes package",
    "text": "4.2 Working with hrbrthemes package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                  color=\"grey25\", fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. This “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                  color=\"grey25\", fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 20, \n              base_size = 15, grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\nAttributes in the theme_ipsum() function\n\n\n\n\naxis_title_size is used to increase the font size of the axis title to 20\nbase_size is used to increase the default axis label to 15\ngrid = \"Y\" is used to remove the x-axis grid lines. If set to “X”, y-axis grid lines will be removed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.1 Creating composite graphics: pathwork methods",
    "text": "5.1 Creating composite graphics: pathwork methods\nOne ggplot2 extension we are exploring in this section is patchwork.\nThe patchwork package has a very simple syntax where we can create layouts easily."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.2 Combining two ggplot2 graphs",
    "text": "5.2 Combining two ggplot2 graphs\nSimply use + to combine 2 plots in a two-column layout!\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.3 Combining three ggplot2 graphs",
    "text": "5.3 Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator to define the sequence of the plotting.\n\n\nLayout 1Layout 2Layout 3\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\np1 | p2 | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.4 Creating a composite figure with tag",
    "text": "5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-an-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-an-insert",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.5 Creating a composite figure with an insert",
    "text": "5.5 Creating a composite figure with an insert\nWith inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2,\n  left = 0.02,\n  bottom = 0.7,\n  right = 0.5,\n  top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "5.6 Creating a composite figure by using patchwork and ggtheme",
    "text": "5.6 Creating a composite figure by using patchwork and ggtheme\n\nApply theme to all plotsApply theme to a single plot\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\n\n\n(p1 / p2) | (p3 + theme_economist())"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to my 10-week ISSS608 Visual Analytics and Applications journey.\nOn this website, you will find my coursework prepared for this course.\nThe road is tough but the following quote motivates me!\n“Everybody, try laughing. Then whatever scares you will go away!” - Tatsuo Kusakabe"
  }
]